{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Korpushersteller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GitHub Repository clonen und in GoogleColab anlegen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/edadunashvili/ThePrax.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ThePrax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein Typ bestimmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "typNum=''\n",
    "episode_string_train = \"gesamt_string_train.csv\"\n",
    "episode_roh_train = \"gesamt_roh_train.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alte Datei mit gleichem Namen löschen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diese Datei existiert nicht\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.path.exists(episode_string_train):\n",
    "    os.remove(episode_string_train)\n",
    "else:\n",
    "    print(\"Diese Datei existiert nicht\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nach den entsprechenden Textdateien im Ordnet suchen und in einer rohe Datei zusammentragen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def word_to_lex(word):\n",
    "    ret=(word) \n",
    "    return ret\n",
    "\n",
    "def write_back(words):\n",
    "    with open(episode_roh_train,\"a\", encoding='utf-8') as output:\n",
    "        for word in words:\n",
    "            #print(word)\n",
    "            as_lex = word_to_lex(word[0])\n",
    "            full_word = '\"' + as_lex + '\"'\n",
    "            for sub_word in word[1:]:\n",
    "                full_word += \" , \"  '\"' + sub_word + '\"'\n",
    "            full_word +=\"\\n\"\n",
    "            output.write(full_word)\n",
    "\n",
    "def clean(line):\n",
    "    line = line.replace(\"\\n\",\" \").strip().lower()\n",
    "    line = line.replace(\"ä\",\"ae\").replace(\"ü\",\"ue\").replace(\"ö\",\"oe\").replace(\"ß\",\"ss\").replace(\",\",\"\").replace(\"«\",\"\")\n",
    "    line = line.replace(\"»\",\"\").replace(\".\",\"\").replace(\":\",\"\").replace(\";\",\"\").replace('\"',\"\")\n",
    "    line = line.replace(\"?\",\"\").replace(\"!\",\"\").replace(\"á\",\"a\").replace(\",\",\"\").replace(\"\\t\",\" \").replace(\"'\",\"\")\n",
    "    line = line.replace(\"‹\",\"\").replace(\"›\",\"\").replace(\"-\",\" \").replace(\"'('\",\"\").replace(\"')'\",\"\").replace('>','')\n",
    "    line = line.replace(\"    \",\" \").replace(\"   \",\" \").replace(\"  \",\" \").replace('–','').replace('—','').replace('<','')\n",
    "    line = line.replace(\"Â\", \"A\").replace(\"ø\", \"oe\").replace('“','').replace('„','').replace('(','').replace(')','')\n",
    "    line = line.replace(\"‚\", \"\").replace(']','').replace('[','')\n",
    "    if line == \"\": \n",
    "        return\n",
    "    \n",
    "    line=line.split(\"|\")\n",
    "    line[0]=line[0].split(\"|\")[0]\n",
    "    flex=[]\n",
    "    try:\n",
    "        flex=line[1].split(\"\")\n",
    "    except:\n",
    "        pass\n",
    "    value=str(line)\n",
    "    line=str(line)   \n",
    "    flex.append(line)\n",
    "    ret=[]\n",
    "    for i in flex:\n",
    "        ret.append((i,value[0]))\n",
    "    return ret\n",
    "\n",
    "with open(episode_roh_train, \"w\", encoding='utf-8') as output:\n",
    "    output.write (\"quelle,episode,index_string,index_binar\\n\")\n",
    "pairs = []\n",
    "\n",
    "for file in glob.glob(\"Trainingsdaten/*.txt\"):\n",
    "    if typNum in file:\n",
    "        with open(file, 'r', encoding='utf-8') as episode:\n",
    "            for line in episode.readlines():\n",
    "                clean_words = clean(line)\n",
    "                pairs = pairs + clean_words\n",
    "write_back(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rohdatei endgültig überarbeiten und in eine CSV Datei speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin = open(episode_roh_train,'r', encoding ='utf-8')\n",
    "fout = open(episode_string_train, \"wt\", encoding ='utf-8')\n",
    "for kfz in fin:\n",
    "    fout.write(kfz.replace(', \"[\"',\"\").replace('\"[', \"\").replace(']\"',\"\").replace(\"', '\", \"','\").replace(\" '\", \"'\"))                      \n",
    "fin.close()\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liste von einmaligen Episoden erstellen in der CSV Datei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'e301_a_'\n",
      "'e300_c_anfangssituation_ankunft_und_erkundigung_der_not'\n",
      "'e300_e_vorfeld_des_kampfes_bis_zum_sieg'\n",
      "'e300_i_rueckkehr_der_koenigstochter_und_die_suche_nach_dem_held retter'\n",
      "'e300_o_auftritt_des_helden_vor_dem_koenig_bis_zum_ende_der_geschichte'\n",
      "'e554_a_'\n",
      "'eamom_a_'\n",
      "'e516_a_'\n",
      "'e513a_a_'\n",
      "'e302_a_'\n",
      "'e300_g_nach_dem_sieg_bis_zur_trennung_des_befreiers_und_der_befreiten'\n",
      "'e300_k_misshandlung_des_falschen_helden_bis_zur_hochzeitstag'\n",
      "'e328_a_'\n",
      "'ecom_a_'\n",
      "'eundf_a_'\n",
      "'e300_m_rueckkehr_des_helden_ _von_der_erkundung_ueber_die_hochzeit_bis_zum_wiedergewinn_der_aufmerksamkeit'\n",
      "'e303_g_erstes_treffen_mit_der_hexen'\n",
      "'e303_i_vom_erkundigung_der_not_bis_zum_aufbruch_des_helden_zur_hexe'\n",
      "'e303_k_vom_afbruch_zur_hexe_bis_zur_ihren_ueberweltigung'\n",
      "'e303_c_eingangssituation_bis_zur_trennung'\n",
      "'e314_a_'\n",
      "'e850_a_'\n",
      "'e303_m_eifersucht'\n",
      "'e315_a_'\n",
      "'e303_q_rueckkehr_und_finale'\n",
      "'e303_o_erloesung_der_hexe'\n",
      "'e567_a_'\n",
      "'e562_a_'\n",
      "'e550_a_'\n",
      "'e590_a_'\n",
      "'e303_e_ankommen_an_den_fremden_ort_und_eheschliessung'\n",
      "'e555_a_'\n",
      "'303_i_vom_erkundigung_der_not_bis_zum_aufbruch_des_helden_zur_hexe'\n",
      "'eende_a_'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(episode_string_train, encoding='utf-8')\n",
    "from collections import Counter\n",
    "indexliste=Counter(df.index_string)\n",
    "print(*indexliste, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liste von allen Episoden in der CSV Datei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#df = pd.read_csv(episode_string_train, encoding='utf-8')\n",
    "#x='_'\n",
    "#for gesep in (df.index_string):\n",
    "    #if x in gesep:\n",
    "        #print(gesep) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auswerter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elementenstruktur definieren: vorherige Episode - gesuchte Episode - folgende Episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('gesamt_string_train.csv', encoding='utf-8')\n",
    "from collections import Counter\n",
    "\n",
    "def ep_format(ep_full):\n",
    "    return (ep_full.split('_'))[0]\n",
    "\n",
    "def quellenvergleich (df, i1, i2):\n",
    "#     print(df.quelle[i1],df.quelle[i2])\n",
    "    return df.quelle[i1]==df.quelle[i2]\n",
    "\n",
    "def ast(gesep, df):\n",
    "    ep_tree = {}\n",
    "    a_liste = []\n",
    "    z_liste = []  \n",
    "    df_len = len(df.index_string)\n",
    "    for i, ep in enumerate(df.index_string):\n",
    "        if gesep == ep:\n",
    "             #print(i, ep_full)\n",
    "            if (i > 0)&(quellenvergleich(df, i, i-1)):\n",
    "                a = df.index_string[i-1]\n",
    "            else:\n",
    "                a = 'eAnfang_a_'\n",
    "            if (i < df_len - 1):\n",
    "                if not (quellenvergleich(df, i, i+1)):\n",
    "                    z = 'eEnde_a_'\n",
    "                else:        \n",
    "                    z = df.index_string[i+1]\n",
    "            else:\n",
    "                z = 'eEnde_a_'\n",
    "            a_liste.append(a)\n",
    "            z_liste.append(z)\n",
    "    return {gesep: [Counter(a_liste), Counter(z_liste)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alle im Korpus vorhandene Episoden extrahieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alle_aeste(gesep, df):\n",
    "    episoden_baeume = {}\n",
    "    \n",
    "    ep_list = []\n",
    "    for ep_full in df.index_string:  \n",
    "        \n",
    "        ep = ep_format(ep_full)      \n",
    "        if gesep == ep:          \n",
    "            \n",
    "            ep_list.append(ep_full)\n",
    "    for ep in set(ep_list):\n",
    "        episoden_baeume.update(ast(ep,df))\n",
    "    return episoden_baeume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Episoden die gesuchte Episode umlegen und in die Liste in die richrige Reihenfolge darstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_val_printer(d):\n",
    "    for k, v in d.items():\n",
    "        print(v, k, sep=':')\n",
    "    #print()\n",
    "        \n",
    "def baum_printer(baeume: dict, baum: str):\n",
    "    key_val_printer (baeume[baum][0])\n",
    "    \n",
    "    \n",
    "    print(80*'-')\n",
    "    print(sum(baeume[baum][0].values()), baum)\n",
    "    print(80*'-')\n",
    "    key_val_printer(baeume[baum][1]) \n",
    "    \n",
    "            \n",
    "def wald_printer(wald: dict):\n",
    "    for baum in sorted(wald.keys()):\n",
    "        baum_printer (wald, baum)\n",
    "        print('\\n',80*'=','\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die gesuchte Episode bestimmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2:'eundf_a_'\n",
      "1:'e554_a_'\n",
      "1:eAnfang_a_\n",
      "3:'e550_a_'\n",
      "1:'e303_k_vom_afbruch_zur_hexe_bis_zur_ihren_ueberweltigung'\n",
      "--------------------------------------------------------------------------------\n",
      "8 'e550_a_'\n",
      "--------------------------------------------------------------------------------\n",
      "1:'e300_c_anfangssituation_ankunft_und_erkundigung_der_not'\n",
      "2:eEnde_a_\n",
      "1:'e300_e_vorfeld_des_kampfes_bis_zum_sieg'\n",
      "3:'e550_a_'\n",
      "1:'e303_o_erloesung_der_hexe'\n",
      "\n",
      " ================================================================================ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "synop = alle_aeste(\"'e300\", df)\n",
    "wald_printer(synop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
