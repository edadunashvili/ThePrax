{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "ThePrax.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4HCoHlAIy--",
        "colab_type": "text"
      },
      "source": [
        "## Umgebung vorbereiten"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zke_8r6QIy_A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "2d583e60-2a25-458f-9a0b-0797639a48df"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDScjC9rIy_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "9f4427cd-806b-4e5f-f4ba-33297b1349d5"
      },
      "source": [
        "!git clone https://github.com/edadunashvili/ThePrax.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'ThePrax' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOHhCppxIy_L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "74b48201-f696-4bc4-9fb8-335a1287fcc4"
      },
      "source": [
        "cd ThePrax"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ThePrax\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTJSjHSFIy_P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "2e95412f-c28f-46d7-e807-2474a4309db7"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ThePrax\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIU1wymiIy_T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3214eb9e-1306-4f07-ae08-da025d57372b"
      },
      "source": [
        "!pip install pyprind"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyprind in /usr/local/lib/python3.6/dist-packages (2.11.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAamUm-8Iy_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wddwrgusIy_b",
        "colab_type": "text"
      },
      "source": [
        "## Korpus von Trainingsdaten erstellen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfiyNAQnIy_c",
        "colab_type": "text"
      },
      "source": [
        " !!! Den gesuchten Typ bestimmen !!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXLsqmg4Iy_d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c9197033-af24-4cea-e207-3d6351e68def"
      },
      "source": [
        "typNum='300'\n",
        "episode_string_train = \"a300_string_train.csv\"\n",
        "episode_roh_train = \"a300_roh_train.csv\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEFZY4kxIy_j",
        "colab_type": "text"
      },
      "source": [
        "Vorhandener gleichnamiger Korpus wird gelöscht "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mohTfciIy_k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "36717191-b3b3-4938-dd7f-57d6bf245c1f"
      },
      "source": [
        "import os\n",
        "if os.path.exists(episode_string_train):\n",
        "    os.remove(episode_string_train)\n",
        "else:\n",
        "    print(\"Diese Datei existiert nicht\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGAYIQ1bIy_o",
        "colab_type": "text"
      },
      "source": [
        "Im Ordner \"Trainingsdaten\" nach den entsprechenden Textdateien suchen und in einer rohe Datei zusammentragen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TlYIcnaIy_p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "dd1b7cd0-6027-4189-de7d-5da1b4e288e5"
      },
      "source": [
        "import glob\n",
        "\n",
        "def word_to_lex(word):\n",
        "    ret=(word) \n",
        "    return ret\n",
        "\n",
        "def write_back(words):\n",
        "    with open(episode_roh_train,\"a\", encoding='utf-8') as output:\n",
        "        for word in words:\n",
        "            #print(word)\n",
        "            as_lex = word_to_lex(word[0])\n",
        "            full_word = '\"' + as_lex + '\"'\n",
        "            for sub_word in word[1:]:\n",
        "                full_word += \" , \"  '\"' + sub_word + '\"'\n",
        "            full_word +=\"\\n\"\n",
        "            output.write(full_word)\n",
        "\n",
        "def clean(line):\n",
        "    line = line.replace(\"\\n\",\" \").strip().lower()\n",
        "    line = line.replace(\"ä\",\"ae\").replace(\"ü\",\"ue\").replace(\"ö\",\"oe\").replace(\"ß\",\"ss\").replace(\",\",\"\").replace(\"«\",\"\")\n",
        "    line = line.replace(\"»\",\"\").replace(\".\",\"\").replace(\":\",\"\").replace(\";\",\"\").replace('\"',\"\")\n",
        "    line = line.replace(\"?\",\"\").replace(\"!\",\"\").replace(\"á\",\"a\").replace(\",\",\"\").replace(\"\\t\",\" \").replace(\"'\",\"\")\n",
        "    line = line.replace(\"‹\",\"\").replace(\"›\",\"\").replace(\"-\",\" \").replace(\"'('\",\"\").replace(\"')'\",\"\").replace('>','')\n",
        "    line = line.replace(\"    \",\" \").replace(\"   \",\" \").replace(\"  \",\" \").replace('–','').replace('—','').replace('<','')\n",
        "    line = line.replace(\"Â\", \"A\").replace(\"ø\", \"oe\").replace('“','').replace('„','').replace('(','').replace(')','')\n",
        "    line = line.replace(\"‚\", \"\").replace(']','').replace('[','')\n",
        "    if line == \"\": \n",
        "        return\n",
        "    \n",
        "    line=line.split(\"|\")\n",
        "    line[0]=line[0].split(\"|\")[0]\n",
        "    flex=[]\n",
        "    try:\n",
        "        flex=line[1].split(\"\")\n",
        "    except:\n",
        "        pass\n",
        "    value=str(line)\n",
        "    line=str(line)   \n",
        "    flex.append(line)\n",
        "    ret=[]\n",
        "    for i in flex:\n",
        "        ret.append((i,value[0]))\n",
        "    return ret\n",
        "\n",
        "with open(episode_roh_train, \"w\", encoding='utf-8') as output:\n",
        "    output.write (\"quelle,episode,index_string,index_binar\\n\")\n",
        "pairs = []\n",
        "\n",
        "\n",
        "for file in glob.glob(\"Trainingsdaten/*.txt\"):\n",
        "    \n",
        "    if typNum in file:\n",
        "        with open(file, 'r', encoding='utf-8') as episode:\n",
        "            for line in episode.readlines():\n",
        "                clean_words = clean(line)\n",
        "                pairs = pairs + clean_words\n",
        "write_back(pairs)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2hACYC_Iy_s",
        "colab_type": "text"
      },
      "source": [
        "Rohdatei endgültig überarbeiten und in eine CSV Datei speichern"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKnutMiTIy_t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "9fb6c56b-16e9-48a1-b2f9-224c0010283d"
      },
      "source": [
        "fin = open(episode_roh_train,'r', encoding ='utf-8')\n",
        "fout = open(episode_string_train, \"wt\", encoding ='utf-8')\n",
        "for kfz in fin:\n",
        "    fout.write(kfz.replace(', \"[\"',\"\").replace('\"[', \"\").replace(']\"',\"\").replace(\"', '\", \"','\").replace(\" '\", \"'\"))                      \n",
        "fin.close()\n",
        "fout.close()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ew6VvQ1LIy_w",
        "colab_type": "text"
      },
      "source": [
        "Liste von einmaligen Episoden aus der CSV Datei zeigen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "xmxpy25rIy_x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "6f19d4c6-791b-4a7a-dfc0-681d99c98189"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(episode_string_train, encoding='utf-8')\n",
        "from collections import Counter\n",
        "indexliste=Counter(df.index_string)\n",
        "print(indexliste, sep='\\n')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Counter({\"'e300_e_vorfeld_des_kampfes_bis_zum_sieg'\": 41, \"'e300_c_anfangssituation_ankunft_und_erkundigung_der_not'\": 36, \"'e300_o_auftritt_des_helden_vor_dem_koenig_bis_zum_ende_der_geschichte'\": 34, \"'e300_g_nach_dem_sieg_bis_zur_trennung_des_befreiers_und_der_befreiten'\": 30, \"'e300_k_misshandlung_des_falschen_helden_bis_zur_hochzeitstag'\": 28, \"'e554_a_'\": 20, \"'e300_m_rueckkehr_des_helden_ _von_der_erkundung_ueber_die_hochzeit_bis_zum_wiedergewinn_der_aufmerksamkeit'\": 19, \"'e303_c_eingangssituation_bis_zur_trennung'\": 16, \"'e303_g_erstes_treffen_mit_der_hexen'\": 16, \"'e303_i_vom_erkundigung_der_not_bis_zum_aufbruch_des_helden_zur_hexe'\": 15, \"'e303_k_vom_afbruch_zur_hexe_bis_zur_ihren_ueberweltigung'\": 15, \"'eundf_a_'\": 13, \"'e315_a_'\": 12, \"'ecom_a_'\": 11, \"'e300_l_wiederbelebung_des_helden'\": 8, \"'e550_a_'\": 7, \"'e300_i_rueckkehr_der_koenigstochter_und_die_suche_nach_dem_held retter'\": 7, \"'e301_a_'\": 7, \"'e562_a_'\": 6, \"'e303_m_eifersucht'\": 5, \"'e328_a_'\": 4, \"'e303_q_rueckkehr_und_finale'\": 4, \"'e567_a_'\": 3, \"'e516_a_'\": 2, \"'e513a_a_'\": 2, \"'e302_a_'\": 2, \"'eamom_a_'\": 1, \"'e590_a_'\": 1, \"'e303_o_erloesung_der_hexe'\": 1, \"'e314_a_'\": 1, \"'e850_a_'\": 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lf4WWHtVIy_2",
        "colab_type": "text"
      },
      "source": [
        "## Modell erstellen und trainieren"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q58fC2M_Iy_2",
        "colab_type": "text"
      },
      "source": [
        "Bibliotheken laden"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2wMViuVIy_3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "415653bc-ac54-4ba1-df13-2bb7a1ab2416"
      },
      "source": [
        "import keras\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pyprind\n",
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "import string\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from keras import backend as K\n",
        "from keras import layers\n",
        "from keras import losses\n",
        "from keras import models\n",
        "from keras import metrics\n",
        "from keras import optimizers\n",
        "from keras.preprocessing import sequence"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3S74327Iy_6",
        "colab_type": "text"
      },
      "source": [
        "!!! Variable anpassen !!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxasG_kZIy_7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "2f70714a-81cc-4b56-9319-6fe84a6a47cd"
      },
      "source": [
        "ziel_episode = 'e300_c_anfangssituation_ankunft_und_erkundigung_der_not'\n",
        "mini_frequenz = 2\n",
        "k_fach = 5\n",
        "layD = 96\n",
        "episode_string_train = 'a300_string_train.csv' \n",
        "episode_binar_train = 'a300_binar_train.csv'"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0oB6FNkIy_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eRjSfTkIzAB",
        "colab_type": "text"
      },
      "source": [
        "Aufbereitung der Trainingsdaten.\n",
        "Rohdaten laden und und den Episodenbestand betrachten"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrYBGds_IzAB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "05fd8d69-da71-4201-e50f-07b4250db437"
      },
      "source": [
        "fin = open(episode_string_train,'r', encoding='utf-8') \n",
        "fout = open(episode_binar_train, \"wt\", encoding='utf-8')\n",
        "for efz in fin:\n",
        "    fout.write(efz.replace(\"'\",\"\"))  \n",
        "fin.close()\n",
        "fout.close()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V3OmzBHIzAE",
        "colab_type": "text"
      },
      "source": [
        "Die in der CSV Datei etikettierte Episoden auflisten"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fu7nHKAyIzAG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "34302529-416a-486f-e9d5-c1b8bb7f2a66"
      },
      "source": [
        "df = pd.read_csv(episode_binar_train, encoding='utf-8')\n",
        "indexliste=Counter(df.index_string)\n",
        "print(*indexliste, sep='\\n')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "ecom_a_\n",
            "e303_c_eingangssituation_bis_zur_trennung\n",
            "e300_c_anfangssituation_ankunft_und_erkundigung_der_not\n",
            "e300_e_vorfeld_des_kampfes_bis_zum_sieg\n",
            "e300_g_nach_dem_sieg_bis_zur_trennung_des_befreiers_und_der_befreiten\n",
            "e300_k_misshandlung_des_falschen_helden_bis_zur_hochzeitstag\n",
            "e300_m_rueckkehr_des_helden_ _von_der_erkundung_ueber_die_hochzeit_bis_zum_wiedergewinn_der_aufmerksamkeit\n",
            "e300_o_auftritt_des_helden_vor_dem_koenig_bis_zum_ende_der_geschichte\n",
            "e303_g_erstes_treffen_mit_der_hexen\n",
            "e303_i_vom_erkundigung_der_not_bis_zum_aufbruch_des_helden_zur_hexe\n",
            "e303_k_vom_afbruch_zur_hexe_bis_zur_ihren_ueberweltigung\n",
            "e315_a_\n",
            "e554_a_\n",
            "e550_a_\n",
            "eundf_a_\n",
            "e300_i_rueckkehr_der_koenigstochter_und_die_suche_nach_dem_held retter\n",
            "eamom_a_\n",
            "e516_a_\n",
            "e513a_a_\n",
            "e302_a_\n",
            "e301_a_\n",
            "e300_l_wiederbelebung_des_helden\n",
            "e328_a_\n",
            "e567_a_\n",
            "e590_a_\n",
            "e303_m_eifersucht\n",
            "e303_o_erloesung_der_hexe\n",
            "e303_q_rueckkehr_und_finale\n",
            "e562_a_\n",
            "e314_a_\n",
            "e850_a_\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSdYNpK8IzAL",
        "colab_type": "text"
      },
      "source": [
        "Die gesuchte Episode etikettieren und den Rohdaten in Trainingsdaten umwandeln"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhE1y-1bIzAM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "716cdf13-2a31-46ba-ee13-0a610f5005ae"
      },
      "source": [
        "for i,e in enumerate(df.index_string):\n",
        "    if e == ziel_episode:\n",
        "        df.index_binar[i]='1'\n",
        "    else: \n",
        "        df.index_binar[i]='0'"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpNTXqfTIzAQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "233f99d8-efc6-4515-ad7a-880f2240963a"
      },
      "source": [
        "df.to_csv(episode_binar_train, encoding='utf-8', index=False)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zO49jEmkIzAT",
        "colab_type": "text"
      },
      "source": [
        "Trainngsdaten aufbereiten. Das Vorkommen jedes Wortes zählen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf8fO94IIzAU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "8b9846eb-f24a-405c-9dd3-28aeb14e4977"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "w = stopwords.words('german')\n",
        "counts = Counter()\n",
        "pbar = pyprind.ProgBar(len(df['episode']),\n",
        "                       title='Vorkommen der Wörter zählen')\n",
        "for i, episode in enumerate(df['episode']): \n",
        "        pbar.update()\n",
        "        counts.update(episode.split())\n",
        "new_counts = {}\n",
        "for k, v in counts.items():\n",
        "    if v > mini_frequenz and k not in w:\n",
        "        new_counts[k] = v\n",
        "counts = Counter(new_counts)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Vorkommen der Wörter zählen\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "0% [##############################] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:00:00\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ntxh_2ISIzAX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e947b19e-391f-48e4-82d5-1f7a0c8772db"
      },
      "source": [
        "#print(counts)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3X1oFlFIzAa",
        "colab_type": "text"
      },
      "source": [
        "Zuordnung erzeugen und den verschiedenen Wörtern eindeutige Zahlen zuordnen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92-Bmh8WIzAb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "70830c5f-bf0e-40a0-e237-50007c60f2dc"
      },
      "source": [
        "word_counts = sorted(counts, key=counts.get, reverse=True)\n",
        "word_to_int = {word: ii for ii, word in enumerate(word_counts,0)}\n",
        "mapped_episoden = []\n",
        "pbar = pyprind.ProgBar(len(df['episode']),\n",
        "                       title='Episoden Zahlen zuordnen')\n",
        "for episode in df['episode']:\n",
        "    mapped_episoden.append([word_to_int.get(word) for word in episode.split()])\n",
        "    pbar.update()\n",
        "mapped_episoden = [list(filter(None, el)) for el in mapped_episoden]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Episoden Zahlen zuordnen\n",
            "0% [##############################] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:00:00\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f956807IzAe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "7108ab5f-f056-4158-9165-5a622ef0c84d"
      },
      "source": [
        "#print(word_to_int)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hVVyV1vIzAj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "bbffc872-d027-434e-e4f8-d3cbd413506d"
      },
      "source": [
        "#print(mapped_episoden[0])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfgS0gIjIzAo",
        "colab_type": "text"
      },
      "source": [
        "Traiingsndaten und Trainingslabels bestimmen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSCqiRdeIzAp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ef0341a0-cc3e-4504-b3e6-0797db512744"
      },
      "source": [
        "train_data = mapped_episoden[0:] \n",
        "train_labels = df.loc[0:, 'index_binar'].values\n",
        "print(\"sequences =\",max([max(sequences) for sequences in mapped_episoden if len(sequences)>0]),\" \",\n",
        "      \"train_data =\", len (train_data))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "sequences = 2593   train_data = 368\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PB3eYKHSIzAs",
        "colab_type": "text"
      },
      "source": [
        "Trainingsdaten und -Labels vektorisieren"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRWHL5iBIzAs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f3297fb4-1ae8-4159-f276-e9e8136ecb68"
      },
      "source": [
        "sequences_laenge=max([max(sequences) for sequences in mapped_episoden if len(sequences)>0])\n",
        "def vectorize_sequences(sequences, dimension=sequences_laenge+1): \n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.\n",
        "    return results\n",
        "x_train = vectorize_sequences(train_data) \n",
        "y_train = np.asarray(train_labels).astype('float32')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4-ontDlIzAv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c97de183-6c5e-4889-840d-571ce35b23e9"
      },
      "source": [
        "for i, element in enumerate(x_train[0]):\n",
        "    print(i,'-', element)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0 - 0.0\n",
            "1 - 1.0\n",
            "2 - 1.0\n",
            "3 - 0.0\n",
            "4 - 0.0\n",
            "5 - 0.0\n",
            "6 - 0.0\n",
            "7 - 0.0\n",
            "8 - 0.0\n",
            "9 - 0.0\n",
            "10 - 0.0\n",
            "11 - 0.0\n",
            "12 - 1.0\n",
            "13 - 0.0\n",
            "14 - 0.0\n",
            "15 - 0.0\n",
            "16 - 1.0\n",
            "17 - 0.0\n",
            "18 - 0.0\n",
            "19 - 0.0\n",
            "20 - 0.0\n",
            "21 - 0.0\n",
            "22 - 0.0\n",
            "23 - 0.0\n",
            "24 - 0.0\n",
            "25 - 0.0\n",
            "26 - 0.0\n",
            "27 - 0.0\n",
            "28 - 1.0\n",
            "29 - 1.0\n",
            "30 - 0.0\n",
            "31 - 0.0\n",
            "32 - 0.0\n",
            "33 - 0.0\n",
            "34 - 0.0\n",
            "35 - 1.0\n",
            "36 - 0.0\n",
            "37 - 0.0\n",
            "38 - 0.0\n",
            "39 - 0.0\n",
            "40 - 0.0\n",
            "41 - 0.0\n",
            "42 - 0.0\n",
            "43 - 0.0\n",
            "44 - 0.0\n",
            "45 - 0.0\n",
            "46 - 0.0\n",
            "47 - 0.0\n",
            "48 - 0.0\n",
            "49 - 1.0\n",
            "50 - 0.0\n",
            "51 - 0.0\n",
            "52 - 0.0\n",
            "53 - 0.0\n",
            "54 - 0.0\n",
            "55 - 0.0\n",
            "56 - 0.0\n",
            "57 - 0.0\n",
            "58 - 0.0\n",
            "59 - 0.0\n",
            "60 - 0.0\n",
            "61 - 0.0\n",
            "62 - 1.0\n",
            "63 - 0.0\n",
            "64 - 0.0\n",
            "65 - 0.0\n",
            "66 - 0.0\n",
            "67 - 0.0\n",
            "68 - 0.0\n",
            "69 - 0.0\n",
            "70 - 0.0\n",
            "71 - 0.0\n",
            "72 - 0.0\n",
            "73 - 0.0\n",
            "74 - 0.0\n",
            "75 - 0.0\n",
            "76 - 0.0\n",
            "77 - 0.0\n",
            "78 - 0.0\n",
            "79 - 0.0\n",
            "80 - 0.0\n",
            "81 - 0.0\n",
            "82 - 0.0\n",
            "83 - 0.0\n",
            "84 - 0.0\n",
            "85 - 0.0\n",
            "86 - 1.0\n",
            "87 - 0.0\n",
            "88 - 0.0\n",
            "89 - 0.0\n",
            "90 - 0.0\n",
            "91 - 0.0\n",
            "92 - 0.0\n",
            "93 - 0.0\n",
            "94 - 0.0\n",
            "95 - 0.0\n",
            "96 - 0.0\n",
            "97 - 0.0\n",
            "98 - 0.0\n",
            "99 - 0.0\n",
            "100 - 0.0\n",
            "101 - 0.0\n",
            "102 - 0.0\n",
            "103 - 0.0\n",
            "104 - 0.0\n",
            "105 - 0.0\n",
            "106 - 0.0\n",
            "107 - 0.0\n",
            "108 - 0.0\n",
            "109 - 0.0\n",
            "110 - 0.0\n",
            "111 - 0.0\n",
            "112 - 0.0\n",
            "113 - 0.0\n",
            "114 - 0.0\n",
            "115 - 0.0\n",
            "116 - 0.0\n",
            "117 - 1.0\n",
            "118 - 0.0\n",
            "119 - 0.0\n",
            "120 - 0.0\n",
            "121 - 0.0\n",
            "122 - 0.0\n",
            "123 - 0.0\n",
            "124 - 0.0\n",
            "125 - 0.0\n",
            "126 - 0.0\n",
            "127 - 0.0\n",
            "128 - 0.0\n",
            "129 - 0.0\n",
            "130 - 0.0\n",
            "131 - 0.0\n",
            "132 - 0.0\n",
            "133 - 0.0\n",
            "134 - 0.0\n",
            "135 - 0.0\n",
            "136 - 0.0\n",
            "137 - 0.0\n",
            "138 - 0.0\n",
            "139 - 0.0\n",
            "140 - 0.0\n",
            "141 - 0.0\n",
            "142 - 0.0\n",
            "143 - 0.0\n",
            "144 - 0.0\n",
            "145 - 0.0\n",
            "146 - 0.0\n",
            "147 - 0.0\n",
            "148 - 0.0\n",
            "149 - 1.0\n",
            "150 - 0.0\n",
            "151 - 0.0\n",
            "152 - 0.0\n",
            "153 - 0.0\n",
            "154 - 0.0\n",
            "155 - 0.0\n",
            "156 - 0.0\n",
            "157 - 0.0\n",
            "158 - 0.0\n",
            "159 - 0.0\n",
            "160 - 0.0\n",
            "161 - 0.0\n",
            "162 - 0.0\n",
            "163 - 0.0\n",
            "164 - 0.0\n",
            "165 - 0.0\n",
            "166 - 0.0\n",
            "167 - 0.0\n",
            "168 - 0.0\n",
            "169 - 0.0\n",
            "170 - 0.0\n",
            "171 - 1.0\n",
            "172 - 0.0\n",
            "173 - 0.0\n",
            "174 - 0.0\n",
            "175 - 0.0\n",
            "176 - 0.0\n",
            "177 - 0.0\n",
            "178 - 0.0\n",
            "179 - 1.0\n",
            "180 - 0.0\n",
            "181 - 0.0\n",
            "182 - 0.0\n",
            "183 - 0.0\n",
            "184 - 0.0\n",
            "185 - 0.0\n",
            "186 - 0.0\n",
            "187 - 0.0\n",
            "188 - 0.0\n",
            "189 - 0.0\n",
            "190 - 0.0\n",
            "191 - 0.0\n",
            "192 - 0.0\n",
            "193 - 0.0\n",
            "194 - 0.0\n",
            "195 - 0.0\n",
            "196 - 0.0\n",
            "197 - 0.0\n",
            "198 - 0.0\n",
            "199 - 0.0\n",
            "200 - 0.0\n",
            "201 - 0.0\n",
            "202 - 0.0\n",
            "203 - 0.0\n",
            "204 - 0.0\n",
            "205 - 0.0\n",
            "206 - 0.0\n",
            "207 - 0.0\n",
            "208 - 0.0\n",
            "209 - 0.0\n",
            "210 - 0.0\n",
            "211 - 0.0\n",
            "212 - 0.0\n",
            "213 - 0.0\n",
            "214 - 0.0\n",
            "215 - 0.0\n",
            "216 - 0.0\n",
            "217 - 0.0\n",
            "218 - 0.0\n",
            "219 - 0.0\n",
            "220 - 1.0\n",
            "221 - 1.0\n",
            "222 - 0.0\n",
            "223 - 0.0\n",
            "224 - 0.0\n",
            "225 - 0.0\n",
            "226 - 0.0\n",
            "227 - 0.0\n",
            "228 - 0.0\n",
            "229 - 0.0\n",
            "230 - 0.0\n",
            "231 - 0.0\n",
            "232 - 0.0\n",
            "233 - 0.0\n",
            "234 - 0.0\n",
            "235 - 0.0\n",
            "236 - 0.0\n",
            "237 - 0.0\n",
            "238 - 0.0\n",
            "239 - 0.0\n",
            "240 - 0.0\n",
            "241 - 0.0\n",
            "242 - 0.0\n",
            "243 - 0.0\n",
            "244 - 0.0\n",
            "245 - 0.0\n",
            "246 - 1.0\n",
            "247 - 0.0\n",
            "248 - 0.0\n",
            "249 - 0.0\n",
            "250 - 0.0\n",
            "251 - 0.0\n",
            "252 - 0.0\n",
            "253 - 0.0\n",
            "254 - 0.0\n",
            "255 - 0.0\n",
            "256 - 0.0\n",
            "257 - 0.0\n",
            "258 - 0.0\n",
            "259 - 0.0\n",
            "260 - 0.0\n",
            "261 - 0.0\n",
            "262 - 0.0\n",
            "263 - 0.0\n",
            "264 - 0.0\n",
            "265 - 0.0\n",
            "266 - 0.0\n",
            "267 - 0.0\n",
            "268 - 0.0\n",
            "269 - 0.0\n",
            "270 - 0.0\n",
            "271 - 0.0\n",
            "272 - 0.0\n",
            "273 - 0.0\n",
            "274 - 0.0\n",
            "275 - 0.0\n",
            "276 - 0.0\n",
            "277 - 0.0\n",
            "278 - 0.0\n",
            "279 - 0.0\n",
            "280 - 0.0\n",
            "281 - 0.0\n",
            "282 - 0.0\n",
            "283 - 0.0\n",
            "284 - 0.0\n",
            "285 - 0.0\n",
            "286 - 0.0\n",
            "287 - 1.0\n",
            "288 - 0.0\n",
            "289 - 0.0\n",
            "290 - 0.0\n",
            "291 - 0.0\n",
            "292 - 0.0\n",
            "293 - 0.0\n",
            "294 - 0.0\n",
            "295 - 0.0\n",
            "296 - 0.0\n",
            "297 - 0.0\n",
            "298 - 0.0\n",
            "299 - 0.0\n",
            "300 - 0.0\n",
            "301 - 0.0\n",
            "302 - 0.0\n",
            "303 - 0.0\n",
            "304 - 0.0\n",
            "305 - 0.0\n",
            "306 - 0.0\n",
            "307 - 0.0\n",
            "308 - 0.0\n",
            "309 - 0.0\n",
            "310 - 0.0\n",
            "311 - 0.0\n",
            "312 - 0.0\n",
            "313 - 0.0\n",
            "314 - 0.0\n",
            "315 - 0.0\n",
            "316 - 0.0\n",
            "317 - 0.0\n",
            "318 - 0.0\n",
            "319 - 0.0\n",
            "320 - 0.0\n",
            "321 - 0.0\n",
            "322 - 0.0\n",
            "323 - 0.0\n",
            "324 - 0.0\n",
            "325 - 0.0\n",
            "326 - 0.0\n",
            "327 - 0.0\n",
            "328 - 0.0\n",
            "329 - 0.0\n",
            "330 - 0.0\n",
            "331 - 0.0\n",
            "332 - 0.0\n",
            "333 - 0.0\n",
            "334 - 0.0\n",
            "335 - 0.0\n",
            "336 - 0.0\n",
            "337 - 0.0\n",
            "338 - 0.0\n",
            "339 - 0.0\n",
            "340 - 0.0\n",
            "341 - 0.0\n",
            "342 - 0.0\n",
            "343 - 0.0\n",
            "344 - 0.0\n",
            "345 - 0.0\n",
            "346 - 0.0\n",
            "347 - 0.0\n",
            "348 - 0.0\n",
            "349 - 0.0\n",
            "350 - 0.0\n",
            "351 - 0.0\n",
            "352 - 0.0\n",
            "353 - 0.0\n",
            "354 - 0.0\n",
            "355 - 0.0\n",
            "356 - 0.0\n",
            "357 - 0.0\n",
            "358 - 0.0\n",
            "359 - 0.0\n",
            "360 - 0.0\n",
            "361 - 0.0\n",
            "362 - 0.0\n",
            "363 - 0.0\n",
            "364 - 0.0\n",
            "365 - 0.0\n",
            "366 - 0.0\n",
            "367 - 0.0\n",
            "368 - 0.0\n",
            "369 - 0.0\n",
            "370 - 0.0\n",
            "371 - 0.0\n",
            "372 - 0.0\n",
            "373 - 0.0\n",
            "374 - 0.0\n",
            "375 - 0.0\n",
            "376 - 0.0\n",
            "377 - 0.0\n",
            "378 - 0.0\n",
            "379 - 0.0\n",
            "380 - 0.0\n",
            "381 - 0.0\n",
            "382 - 0.0\n",
            "383 - 0.0\n",
            "384 - 0.0\n",
            "385 - 0.0\n",
            "386 - 0.0\n",
            "387 - 0.0\n",
            "388 - 0.0\n",
            "389 - 0.0\n",
            "390 - 0.0\n",
            "391 - 0.0\n",
            "392 - 0.0\n",
            "393 - 0.0\n",
            "394 - 0.0\n",
            "395 - 0.0\n",
            "396 - 0.0\n",
            "397 - 0.0\n",
            "398 - 0.0\n",
            "399 - 0.0\n",
            "400 - 0.0\n",
            "401 - 0.0\n",
            "402 - 1.0\n",
            "403 - 0.0\n",
            "404 - 0.0\n",
            "405 - 0.0\n",
            "406 - 0.0\n",
            "407 - 0.0\n",
            "408 - 0.0\n",
            "409 - 0.0\n",
            "410 - 0.0\n",
            "411 - 0.0\n",
            "412 - 0.0\n",
            "413 - 0.0\n",
            "414 - 0.0\n",
            "415 - 0.0\n",
            "416 - 0.0\n",
            "417 - 0.0\n",
            "418 - 0.0\n",
            "419 - 0.0\n",
            "420 - 0.0\n",
            "421 - 0.0\n",
            "422 - 0.0\n",
            "423 - 0.0\n",
            "424 - 0.0\n",
            "425 - 0.0\n",
            "426 - 0.0\n",
            "427 - 0.0\n",
            "428 - 0.0\n",
            "429 - 0.0\n",
            "430 - 0.0\n",
            "431 - 0.0\n",
            "432 - 0.0\n",
            "433 - 0.0\n",
            "434 - 0.0\n",
            "435 - 0.0\n",
            "436 - 0.0\n",
            "437 - 0.0\n",
            "438 - 0.0\n",
            "439 - 0.0\n",
            "440 - 0.0\n",
            "441 - 0.0\n",
            "442 - 0.0\n",
            "443 - 1.0\n",
            "444 - 0.0\n",
            "445 - 0.0\n",
            "446 - 0.0\n",
            "447 - 0.0\n",
            "448 - 0.0\n",
            "449 - 0.0\n",
            "450 - 0.0\n",
            "451 - 0.0\n",
            "452 - 0.0\n",
            "453 - 0.0\n",
            "454 - 0.0\n",
            "455 - 0.0\n",
            "456 - 0.0\n",
            "457 - 0.0\n",
            "458 - 0.0\n",
            "459 - 0.0\n",
            "460 - 0.0\n",
            "461 - 0.0\n",
            "462 - 0.0\n",
            "463 - 0.0\n",
            "464 - 0.0\n",
            "465 - 0.0\n",
            "466 - 0.0\n",
            "467 - 0.0\n",
            "468 - 0.0\n",
            "469 - 1.0\n",
            "470 - 1.0\n",
            "471 - 1.0\n",
            "472 - 0.0\n",
            "473 - 0.0\n",
            "474 - 0.0\n",
            "475 - 0.0\n",
            "476 - 0.0\n",
            "477 - 0.0\n",
            "478 - 0.0\n",
            "479 - 0.0\n",
            "480 - 0.0\n",
            "481 - 0.0\n",
            "482 - 0.0\n",
            "483 - 0.0\n",
            "484 - 0.0\n",
            "485 - 0.0\n",
            "486 - 0.0\n",
            "487 - 0.0\n",
            "488 - 0.0\n",
            "489 - 0.0\n",
            "490 - 0.0\n",
            "491 - 0.0\n",
            "492 - 0.0\n",
            "493 - 0.0\n",
            "494 - 0.0\n",
            "495 - 0.0\n",
            "496 - 0.0\n",
            "497 - 0.0\n",
            "498 - 0.0\n",
            "499 - 0.0\n",
            "500 - 0.0\n",
            "501 - 0.0\n",
            "502 - 0.0\n",
            "503 - 0.0\n",
            "504 - 0.0\n",
            "505 - 0.0\n",
            "506 - 0.0\n",
            "507 - 0.0\n",
            "508 - 0.0\n",
            "509 - 0.0\n",
            "510 - 0.0\n",
            "511 - 0.0\n",
            "512 - 0.0\n",
            "513 - 0.0\n",
            "514 - 0.0\n",
            "515 - 0.0\n",
            "516 - 0.0\n",
            "517 - 0.0\n",
            "518 - 0.0\n",
            "519 - 0.0\n",
            "520 - 0.0\n",
            "521 - 0.0\n",
            "522 - 0.0\n",
            "523 - 0.0\n",
            "524 - 0.0\n",
            "525 - 0.0\n",
            "526 - 0.0\n",
            "527 - 0.0\n",
            "528 - 0.0\n",
            "529 - 0.0\n",
            "530 - 0.0\n",
            "531 - 0.0\n",
            "532 - 0.0\n",
            "533 - 0.0\n",
            "534 - 0.0\n",
            "535 - 0.0\n",
            "536 - 0.0\n",
            "537 - 0.0\n",
            "538 - 0.0\n",
            "539 - 0.0\n",
            "540 - 0.0\n",
            "541 - 0.0\n",
            "542 - 0.0\n",
            "543 - 0.0\n",
            "544 - 0.0\n",
            "545 - 0.0\n",
            "546 - 0.0\n",
            "547 - 0.0\n",
            "548 - 0.0\n",
            "549 - 0.0\n",
            "550 - 0.0\n",
            "551 - 0.0\n",
            "552 - 0.0\n",
            "553 - 0.0\n",
            "554 - 0.0\n",
            "555 - 0.0\n",
            "556 - 0.0\n",
            "557 - 0.0\n",
            "558 - 0.0\n",
            "559 - 0.0\n",
            "560 - 0.0\n",
            "561 - 0.0\n",
            "562 - 0.0\n",
            "563 - 0.0\n",
            "564 - 0.0\n",
            "565 - 0.0\n",
            "566 - 0.0\n",
            "567 - 0.0\n",
            "568 - 0.0\n",
            "569 - 0.0\n",
            "570 - 0.0\n",
            "571 - 0.0\n",
            "572 - 0.0\n",
            "573 - 0.0\n",
            "574 - 0.0\n",
            "575 - 0.0\n",
            "576 - 0.0\n",
            "577 - 0.0\n",
            "578 - 0.0\n",
            "579 - 0.0\n",
            "580 - 0.0\n",
            "581 - 0.0\n",
            "582 - 0.0\n",
            "583 - 0.0\n",
            "584 - 0.0\n",
            "585 - 0.0\n",
            "586 - 0.0\n",
            "587 - 0.0\n",
            "588 - 0.0\n",
            "589 - 0.0\n",
            "590 - 0.0\n",
            "591 - 0.0\n",
            "592 - 0.0\n",
            "593 - 0.0\n",
            "594 - 0.0\n",
            "595 - 0.0\n",
            "596 - 0.0\n",
            "597 - 0.0\n",
            "598 - 0.0\n",
            "599 - 0.0\n",
            "600 - 0.0\n",
            "601 - 0.0\n",
            "602 - 0.0\n",
            "603 - 0.0\n",
            "604 - 0.0\n",
            "605 - 0.0\n",
            "606 - 0.0\n",
            "607 - 0.0\n",
            "608 - 0.0\n",
            "609 - 0.0\n",
            "610 - 0.0\n",
            "611 - 0.0\n",
            "612 - 0.0\n",
            "613 - 0.0\n",
            "614 - 0.0\n",
            "615 - 1.0\n",
            "616 - 1.0\n",
            "617 - 1.0\n",
            "618 - 0.0\n",
            "619 - 0.0\n",
            "620 - 0.0\n",
            "621 - 0.0\n",
            "622 - 0.0\n",
            "623 - 0.0\n",
            "624 - 0.0\n",
            "625 - 0.0\n",
            "626 - 0.0\n",
            "627 - 0.0\n",
            "628 - 0.0\n",
            "629 - 0.0\n",
            "630 - 0.0\n",
            "631 - 0.0\n",
            "632 - 0.0\n",
            "633 - 0.0\n",
            "634 - 0.0\n",
            "635 - 0.0\n",
            "636 - 0.0\n",
            "637 - 0.0\n",
            "638 - 0.0\n",
            "639 - 0.0\n",
            "640 - 0.0\n",
            "641 - 0.0\n",
            "642 - 0.0\n",
            "643 - 0.0\n",
            "644 - 0.0\n",
            "645 - 0.0\n",
            "646 - 0.0\n",
            "647 - 0.0\n",
            "648 - 0.0\n",
            "649 - 0.0\n",
            "650 - 0.0\n",
            "651 - 0.0\n",
            "652 - 0.0\n",
            "653 - 0.0\n",
            "654 - 0.0\n",
            "655 - 0.0\n",
            "656 - 0.0\n",
            "657 - 0.0\n",
            "658 - 0.0\n",
            "659 - 0.0\n",
            "660 - 0.0\n",
            "661 - 0.0\n",
            "662 - 0.0\n",
            "663 - 0.0\n",
            "664 - 0.0\n",
            "665 - 0.0\n",
            "666 - 0.0\n",
            "667 - 0.0\n",
            "668 - 0.0\n",
            "669 - 0.0\n",
            "670 - 0.0\n",
            "671 - 0.0\n",
            "672 - 0.0\n",
            "673 - 0.0\n",
            "674 - 0.0\n",
            "675 - 0.0\n",
            "676 - 0.0\n",
            "677 - 0.0\n",
            "678 - 0.0\n",
            "679 - 0.0\n",
            "680 - 0.0\n",
            "681 - 0.0\n",
            "682 - 0.0\n",
            "683 - 0.0\n",
            "684 - 0.0\n",
            "685 - 0.0\n",
            "686 - 0.0\n",
            "687 - 0.0\n",
            "688 - 0.0\n",
            "689 - 0.0\n",
            "690 - 0.0\n",
            "691 - 0.0\n",
            "692 - 0.0\n",
            "693 - 0.0\n",
            "694 - 0.0\n",
            "695 - 0.0\n",
            "696 - 0.0\n",
            "697 - 0.0\n",
            "698 - 0.0\n",
            "699 - 0.0\n",
            "700 - 0.0\n",
            "701 - 0.0\n",
            "702 - 0.0\n",
            "703 - 0.0\n",
            "704 - 0.0\n",
            "705 - 0.0\n",
            "706 - 0.0\n",
            "707 - 0.0\n",
            "708 - 0.0\n",
            "709 - 0.0\n",
            "710 - 0.0\n",
            "711 - 0.0\n",
            "712 - 0.0\n",
            "713 - 0.0\n",
            "714 - 0.0\n",
            "715 - 0.0\n",
            "716 - 0.0\n",
            "717 - 0.0\n",
            "718 - 0.0\n",
            "719 - 0.0\n",
            "720 - 0.0\n",
            "721 - 0.0\n",
            "722 - 0.0\n",
            "723 - 0.0\n",
            "724 - 0.0\n",
            "725 - 0.0\n",
            "726 - 0.0\n",
            "727 - 0.0\n",
            "728 - 0.0\n",
            "729 - 0.0\n",
            "730 - 0.0\n",
            "731 - 0.0\n",
            "732 - 0.0\n",
            "733 - 0.0\n",
            "734 - 0.0\n",
            "735 - 0.0\n",
            "736 - 0.0\n",
            "737 - 0.0\n",
            "738 - 0.0\n",
            "739 - 0.0\n",
            "740 - 0.0\n",
            "741 - 0.0\n",
            "742 - 0.0\n",
            "743 - 0.0\n",
            "744 - 0.0\n",
            "745 - 0.0\n",
            "746 - 0.0\n",
            "747 - 0.0\n",
            "748 - 0.0\n",
            "749 - 0.0\n",
            "750 - 0.0\n",
            "751 - 0.0\n",
            "752 - 0.0\n",
            "753 - 0.0\n",
            "754 - 0.0\n",
            "755 - 0.0\n",
            "756 - 0.0\n",
            "757 - 0.0\n",
            "758 - 0.0\n",
            "759 - 0.0\n",
            "760 - 0.0\n",
            "761 - 0.0\n",
            "762 - 0.0\n",
            "763 - 0.0\n",
            "764 - 0.0\n",
            "765 - 0.0\n",
            "766 - 0.0\n",
            "767 - 0.0\n",
            "768 - 0.0\n",
            "769 - 0.0\n",
            "770 - 0.0\n",
            "771 - 0.0\n",
            "772 - 0.0\n",
            "773 - 0.0\n",
            "774 - 0.0\n",
            "775 - 0.0\n",
            "776 - 0.0\n",
            "777 - 0.0\n",
            "778 - 0.0\n",
            "779 - 0.0\n",
            "780 - 0.0\n",
            "781 - 0.0\n",
            "782 - 0.0\n",
            "783 - 0.0\n",
            "784 - 0.0\n",
            "785 - 0.0\n",
            "786 - 0.0\n",
            "787 - 0.0\n",
            "788 - 0.0\n",
            "789 - 0.0\n",
            "790 - 0.0\n",
            "791 - 0.0\n",
            "792 - 1.0\n",
            "793 - 0.0\n",
            "794 - 0.0\n",
            "795 - 0.0\n",
            "796 - 0.0\n",
            "797 - 0.0\n",
            "798 - 0.0\n",
            "799 - 0.0\n",
            "800 - 0.0\n",
            "801 - 0.0\n",
            "802 - 0.0\n",
            "803 - 0.0\n",
            "804 - 0.0\n",
            "805 - 0.0\n",
            "806 - 0.0\n",
            "807 - 0.0\n",
            "808 - 0.0\n",
            "809 - 0.0\n",
            "810 - 0.0\n",
            "811 - 0.0\n",
            "812 - 0.0\n",
            "813 - 0.0\n",
            "814 - 0.0\n",
            "815 - 0.0\n",
            "816 - 0.0\n",
            "817 - 0.0\n",
            "818 - 0.0\n",
            "819 - 0.0\n",
            "820 - 0.0\n",
            "821 - 0.0\n",
            "822 - 0.0\n",
            "823 - 0.0\n",
            "824 - 0.0\n",
            "825 - 0.0\n",
            "826 - 0.0\n",
            "827 - 0.0\n",
            "828 - 0.0\n",
            "829 - 0.0\n",
            "830 - 0.0\n",
            "831 - 0.0\n",
            "832 - 0.0\n",
            "833 - 0.0\n",
            "834 - 0.0\n",
            "835 - 0.0\n",
            "836 - 0.0\n",
            "837 - 0.0\n",
            "838 - 0.0\n",
            "839 - 0.0\n",
            "840 - 0.0\n",
            "841 - 0.0\n",
            "842 - 0.0\n",
            "843 - 0.0\n",
            "844 - 0.0\n",
            "845 - 0.0\n",
            "846 - 0.0\n",
            "847 - 0.0\n",
            "848 - 0.0\n",
            "849 - 0.0\n",
            "850 - 0.0\n",
            "851 - 0.0\n",
            "852 - 0.0\n",
            "853 - 0.0\n",
            "854 - 0.0\n",
            "855 - 0.0\n",
            "856 - 0.0\n",
            "857 - 0.0\n",
            "858 - 0.0\n",
            "859 - 0.0\n",
            "860 - 0.0\n",
            "861 - 0.0\n",
            "862 - 0.0\n",
            "863 - 0.0\n",
            "864 - 0.0\n",
            "865 - 0.0\n",
            "866 - 0.0\n",
            "867 - 0.0\n",
            "868 - 0.0\n",
            "869 - 0.0\n",
            "870 - 0.0\n",
            "871 - 0.0\n",
            "872 - 0.0\n",
            "873 - 0.0\n",
            "874 - 0.0\n",
            "875 - 0.0\n",
            "876 - 0.0\n",
            "877 - 0.0\n",
            "878 - 0.0\n",
            "879 - 0.0\n",
            "880 - 0.0\n",
            "881 - 0.0\n",
            "882 - 0.0\n",
            "883 - 0.0\n",
            "884 - 0.0\n",
            "885 - 0.0\n",
            "886 - 0.0\n",
            "887 - 0.0\n",
            "888 - 0.0\n",
            "889 - 0.0\n",
            "890 - 0.0\n",
            "891 - 0.0\n",
            "892 - 0.0\n",
            "893 - 0.0\n",
            "894 - 0.0\n",
            "895 - 0.0\n",
            "896 - 0.0\n",
            "897 - 0.0\n",
            "898 - 0.0\n",
            "899 - 0.0\n",
            "900 - 0.0\n",
            "901 - 0.0\n",
            "902 - 0.0\n",
            "903 - 0.0\n",
            "904 - 0.0\n",
            "905 - 0.0\n",
            "906 - 0.0\n",
            "907 - 0.0\n",
            "908 - 0.0\n",
            "909 - 0.0\n",
            "910 - 0.0\n",
            "911 - 0.0\n",
            "912 - 0.0\n",
            "913 - 0.0\n",
            "914 - 0.0\n",
            "915 - 0.0\n",
            "916 - 0.0\n",
            "917 - 0.0\n",
            "918 - 0.0\n",
            "919 - 0.0\n",
            "920 - 0.0\n",
            "921 - 0.0\n",
            "922 - 0.0\n",
            "923 - 0.0\n",
            "924 - 0.0\n",
            "925 - 0.0\n",
            "926 - 0.0\n",
            "927 - 0.0\n",
            "928 - 0.0\n",
            "929 - 0.0\n",
            "930 - 0.0\n",
            "931 - 0.0\n",
            "932 - 0.0\n",
            "933 - 0.0\n",
            "934 - 0.0\n",
            "935 - 0.0\n",
            "936 - 0.0\n",
            "937 - 0.0\n",
            "938 - 0.0\n",
            "939 - 0.0\n",
            "940 - 0.0\n",
            "941 - 0.0\n",
            "942 - 0.0\n",
            "943 - 0.0\n",
            "944 - 0.0\n",
            "945 - 0.0\n",
            "946 - 0.0\n",
            "947 - 0.0\n",
            "948 - 0.0\n",
            "949 - 0.0\n",
            "950 - 0.0\n",
            "951 - 0.0\n",
            "952 - 0.0\n",
            "953 - 0.0\n",
            "954 - 0.0\n",
            "955 - 0.0\n",
            "956 - 1.0\n",
            "957 - 0.0\n",
            "958 - 0.0\n",
            "959 - 0.0\n",
            "960 - 0.0\n",
            "961 - 0.0\n",
            "962 - 0.0\n",
            "963 - 0.0\n",
            "964 - 0.0\n",
            "965 - 0.0\n",
            "966 - 0.0\n",
            "967 - 0.0\n",
            "968 - 0.0\n",
            "969 - 0.0\n",
            "970 - 0.0\n",
            "971 - 0.0\n",
            "972 - 0.0\n",
            "973 - 0.0\n",
            "974 - 0.0\n",
            "975 - 0.0\n",
            "976 - 0.0\n",
            "977 - 0.0\n",
            "978 - 0.0\n",
            "979 - 0.0\n",
            "980 - 0.0\n",
            "981 - 0.0\n",
            "982 - 0.0\n",
            "983 - 0.0\n",
            "984 - 0.0\n",
            "985 - 0.0\n",
            "986 - 0.0\n",
            "987 - 0.0\n",
            "988 - 0.0\n",
            "989 - 0.0\n",
            "990 - 0.0\n",
            "991 - 0.0\n",
            "992 - 0.0\n",
            "993 - 0.0\n",
            "994 - 0.0\n",
            "995 - 0.0\n",
            "996 - 0.0\n",
            "997 - 0.0\n",
            "998 - 0.0\n",
            "999 - 0.0\n",
            "1000 - 0.0\n",
            "1001 - 0.0\n",
            "1002 - 0.0\n",
            "1003 - 0.0\n",
            "1004 - 0.0\n",
            "1005 - 0.0\n",
            "1006 - 0.0\n",
            "1007 - 0.0\n",
            "1008 - 0.0\n",
            "1009 - 0.0\n",
            "1010 - 0.0\n",
            "1011 - 0.0\n",
            "1012 - 0.0\n",
            "1013 - 0.0\n",
            "1014 - 0.0\n",
            "1015 - 0.0\n",
            "1016 - 0.0\n",
            "1017 - 0.0\n",
            "1018 - 0.0\n",
            "1019 - 0.0\n",
            "1020 - 0.0\n",
            "1021 - 0.0\n",
            "1022 - 0.0\n",
            "1023 - 0.0\n",
            "1024 - 0.0\n",
            "1025 - 0.0\n",
            "1026 - 0.0\n",
            "1027 - 0.0\n",
            "1028 - 0.0\n",
            "1029 - 0.0\n",
            "1030 - 0.0\n",
            "1031 - 0.0\n",
            "1032 - 0.0\n",
            "1033 - 0.0\n",
            "1034 - 0.0\n",
            "1035 - 0.0\n",
            "1036 - 0.0\n",
            "1037 - 0.0\n",
            "1038 - 0.0\n",
            "1039 - 0.0\n",
            "1040 - 0.0\n",
            "1041 - 0.0\n",
            "1042 - 0.0\n",
            "1043 - 0.0\n",
            "1044 - 0.0\n",
            "1045 - 0.0\n",
            "1046 - 0.0\n",
            "1047 - 0.0\n",
            "1048 - 0.0\n",
            "1049 - 0.0\n",
            "1050 - 0.0\n",
            "1051 - 0.0\n",
            "1052 - 0.0\n",
            "1053 - 0.0\n",
            "1054 - 0.0\n",
            "1055 - 0.0\n",
            "1056 - 0.0\n",
            "1057 - 0.0\n",
            "1058 - 0.0\n",
            "1059 - 0.0\n",
            "1060 - 0.0\n",
            "1061 - 0.0\n",
            "1062 - 0.0\n",
            "1063 - 0.0\n",
            "1064 - 0.0\n",
            "1065 - 0.0\n",
            "1066 - 1.0\n",
            "1067 - 1.0\n",
            "1068 - 0.0\n",
            "1069 - 0.0\n",
            "1070 - 0.0\n",
            "1071 - 0.0\n",
            "1072 - 0.0\n",
            "1073 - 0.0\n",
            "1074 - 0.0\n",
            "1075 - 0.0\n",
            "1076 - 0.0\n",
            "1077 - 0.0\n",
            "1078 - 0.0\n",
            "1079 - 0.0\n",
            "1080 - 0.0\n",
            "1081 - 0.0\n",
            "1082 - 0.0\n",
            "1083 - 0.0\n",
            "1084 - 0.0\n",
            "1085 - 0.0\n",
            "1086 - 0.0\n",
            "1087 - 0.0\n",
            "1088 - 0.0\n",
            "1089 - 0.0\n",
            "1090 - 0.0\n",
            "1091 - 0.0\n",
            "1092 - 0.0\n",
            "1093 - 0.0\n",
            "1094 - 0.0\n",
            "1095 - 0.0\n",
            "1096 - 0.0\n",
            "1097 - 0.0\n",
            "1098 - 0.0\n",
            "1099 - 0.0\n",
            "1100 - 0.0\n",
            "1101 - 0.0\n",
            "1102 - 0.0\n",
            "1103 - 0.0\n",
            "1104 - 0.0\n",
            "1105 - 0.0\n",
            "1106 - 0.0\n",
            "1107 - 0.0\n",
            "1108 - 0.0\n",
            "1109 - 0.0\n",
            "1110 - 0.0\n",
            "1111 - 0.0\n",
            "1112 - 0.0\n",
            "1113 - 0.0\n",
            "1114 - 0.0\n",
            "1115 - 0.0\n",
            "1116 - 0.0\n",
            "1117 - 0.0\n",
            "1118 - 0.0\n",
            "1119 - 0.0\n",
            "1120 - 0.0\n",
            "1121 - 0.0\n",
            "1122 - 0.0\n",
            "1123 - 0.0\n",
            "1124 - 0.0\n",
            "1125 - 0.0\n",
            "1126 - 0.0\n",
            "1127 - 0.0\n",
            "1128 - 0.0\n",
            "1129 - 0.0\n",
            "1130 - 0.0\n",
            "1131 - 0.0\n",
            "1132 - 0.0\n",
            "1133 - 0.0\n",
            "1134 - 0.0\n",
            "1135 - 0.0\n",
            "1136 - 0.0\n",
            "1137 - 0.0\n",
            "1138 - 0.0\n",
            "1139 - 0.0\n",
            "1140 - 0.0\n",
            "1141 - 0.0\n",
            "1142 - 0.0\n",
            "1143 - 0.0\n",
            "1144 - 0.0\n",
            "1145 - 0.0\n",
            "1146 - 0.0\n",
            "1147 - 0.0\n",
            "1148 - 0.0\n",
            "1149 - 0.0\n",
            "1150 - 0.0\n",
            "1151 - 0.0\n",
            "1152 - 0.0\n",
            "1153 - 0.0\n",
            "1154 - 0.0\n",
            "1155 - 0.0\n",
            "1156 - 0.0\n",
            "1157 - 0.0\n",
            "1158 - 0.0\n",
            "1159 - 0.0\n",
            "1160 - 0.0\n",
            "1161 - 0.0\n",
            "1162 - 0.0\n",
            "1163 - 0.0\n",
            "1164 - 0.0\n",
            "1165 - 0.0\n",
            "1166 - 0.0\n",
            "1167 - 0.0\n",
            "1168 - 0.0\n",
            "1169 - 0.0\n",
            "1170 - 0.0\n",
            "1171 - 0.0\n",
            "1172 - 0.0\n",
            "1173 - 0.0\n",
            "1174 - 0.0\n",
            "1175 - 0.0\n",
            "1176 - 0.0\n",
            "1177 - 0.0\n",
            "1178 - 0.0\n",
            "1179 - 0.0\n",
            "1180 - 0.0\n",
            "1181 - 0.0\n",
            "1182 - 0.0\n",
            "1183 - 0.0\n",
            "1184 - 0.0\n",
            "1185 - 0.0\n",
            "1186 - 0.0\n",
            "1187 - 0.0\n",
            "1188 - 0.0\n",
            "1189 - 0.0\n",
            "1190 - 0.0\n",
            "1191 - 0.0\n",
            "1192 - 0.0\n",
            "1193 - 0.0\n",
            "1194 - 0.0\n",
            "1195 - 0.0\n",
            "1196 - 0.0\n",
            "1197 - 0.0\n",
            "1198 - 0.0\n",
            "1199 - 0.0\n",
            "1200 - 0.0\n",
            "1201 - 0.0\n",
            "1202 - 0.0\n",
            "1203 - 0.0\n",
            "1204 - 0.0\n",
            "1205 - 0.0\n",
            "1206 - 0.0\n",
            "1207 - 0.0\n",
            "1208 - 0.0\n",
            "1209 - 0.0\n",
            "1210 - 0.0\n",
            "1211 - 0.0\n",
            "1212 - 0.0\n",
            "1213 - 0.0\n",
            "1214 - 1.0\n",
            "1215 - 1.0\n",
            "1216 - 1.0\n",
            "1217 - 0.0\n",
            "1218 - 0.0\n",
            "1219 - 0.0\n",
            "1220 - 0.0\n",
            "1221 - 0.0\n",
            "1222 - 0.0\n",
            "1223 - 0.0\n",
            "1224 - 0.0\n",
            "1225 - 0.0\n",
            "1226 - 0.0\n",
            "1227 - 0.0\n",
            "1228 - 0.0\n",
            "1229 - 0.0\n",
            "1230 - 0.0\n",
            "1231 - 0.0\n",
            "1232 - 0.0\n",
            "1233 - 0.0\n",
            "1234 - 0.0\n",
            "1235 - 0.0\n",
            "1236 - 0.0\n",
            "1237 - 0.0\n",
            "1238 - 0.0\n",
            "1239 - 0.0\n",
            "1240 - 0.0\n",
            "1241 - 0.0\n",
            "1242 - 0.0\n",
            "1243 - 0.0\n",
            "1244 - 0.0\n",
            "1245 - 0.0\n",
            "1246 - 0.0\n",
            "1247 - 0.0\n",
            "1248 - 0.0\n",
            "1249 - 0.0\n",
            "1250 - 0.0\n",
            "1251 - 0.0\n",
            "1252 - 0.0\n",
            "1253 - 0.0\n",
            "1254 - 0.0\n",
            "1255 - 0.0\n",
            "1256 - 0.0\n",
            "1257 - 0.0\n",
            "1258 - 0.0\n",
            "1259 - 0.0\n",
            "1260 - 0.0\n",
            "1261 - 0.0\n",
            "1262 - 0.0\n",
            "1263 - 0.0\n",
            "1264 - 0.0\n",
            "1265 - 0.0\n",
            "1266 - 0.0\n",
            "1267 - 0.0\n",
            "1268 - 0.0\n",
            "1269 - 0.0\n",
            "1270 - 0.0\n",
            "1271 - 0.0\n",
            "1272 - 0.0\n",
            "1273 - 0.0\n",
            "1274 - 0.0\n",
            "1275 - 0.0\n",
            "1276 - 0.0\n",
            "1277 - 0.0\n",
            "1278 - 0.0\n",
            "1279 - 0.0\n",
            "1280 - 0.0\n",
            "1281 - 0.0\n",
            "1282 - 0.0\n",
            "1283 - 0.0\n",
            "1284 - 0.0\n",
            "1285 - 0.0\n",
            "1286 - 0.0\n",
            "1287 - 0.0\n",
            "1288 - 0.0\n",
            "1289 - 0.0\n",
            "1290 - 0.0\n",
            "1291 - 0.0\n",
            "1292 - 0.0\n",
            "1293 - 0.0\n",
            "1294 - 0.0\n",
            "1295 - 0.0\n",
            "1296 - 0.0\n",
            "1297 - 0.0\n",
            "1298 - 0.0\n",
            "1299 - 0.0\n",
            "1300 - 0.0\n",
            "1301 - 0.0\n",
            "1302 - 0.0\n",
            "1303 - 0.0\n",
            "1304 - 0.0\n",
            "1305 - 0.0\n",
            "1306 - 0.0\n",
            "1307 - 0.0\n",
            "1308 - 0.0\n",
            "1309 - 0.0\n",
            "1310 - 0.0\n",
            "1311 - 0.0\n",
            "1312 - 0.0\n",
            "1313 - 0.0\n",
            "1314 - 0.0\n",
            "1315 - 0.0\n",
            "1316 - 0.0\n",
            "1317 - 0.0\n",
            "1318 - 0.0\n",
            "1319 - 0.0\n",
            "1320 - 0.0\n",
            "1321 - 0.0\n",
            "1322 - 0.0\n",
            "1323 - 0.0\n",
            "1324 - 0.0\n",
            "1325 - 0.0\n",
            "1326 - 0.0\n",
            "1327 - 0.0\n",
            "1328 - 0.0\n",
            "1329 - 0.0\n",
            "1330 - 0.0\n",
            "1331 - 0.0\n",
            "1332 - 0.0\n",
            "1333 - 0.0\n",
            "1334 - 0.0\n",
            "1335 - 0.0\n",
            "1336 - 0.0\n",
            "1337 - 0.0\n",
            "1338 - 0.0\n",
            "1339 - 0.0\n",
            "1340 - 0.0\n",
            "1341 - 0.0\n",
            "1342 - 0.0\n",
            "1343 - 0.0\n",
            "1344 - 0.0\n",
            "1345 - 0.0\n",
            "1346 - 0.0\n",
            "1347 - 0.0\n",
            "1348 - 0.0\n",
            "1349 - 0.0\n",
            "1350 - 0.0\n",
            "1351 - 0.0\n",
            "1352 - 0.0\n",
            "1353 - 0.0\n",
            "1354 - 0.0\n",
            "1355 - 0.0\n",
            "1356 - 0.0\n",
            "1357 - 0.0\n",
            "1358 - 0.0\n",
            "1359 - 0.0\n",
            "1360 - 0.0\n",
            "1361 - 0.0\n",
            "1362 - 0.0\n",
            "1363 - 0.0\n",
            "1364 - 0.0\n",
            "1365 - 0.0\n",
            "1366 - 0.0\n",
            "1367 - 0.0\n",
            "1368 - 0.0\n",
            "1369 - 0.0\n",
            "1370 - 0.0\n",
            "1371 - 0.0\n",
            "1372 - 0.0\n",
            "1373 - 0.0\n",
            "1374 - 0.0\n",
            "1375 - 0.0\n",
            "1376 - 0.0\n",
            "1377 - 0.0\n",
            "1378 - 0.0\n",
            "1379 - 0.0\n",
            "1380 - 0.0\n",
            "1381 - 0.0\n",
            "1382 - 0.0\n",
            "1383 - 0.0\n",
            "1384 - 0.0\n",
            "1385 - 0.0\n",
            "1386 - 0.0\n",
            "1387 - 0.0\n",
            "1388 - 0.0\n",
            "1389 - 0.0\n",
            "1390 - 0.0\n",
            "1391 - 0.0\n",
            "1392 - 1.0\n",
            "1393 - 0.0\n",
            "1394 - 0.0\n",
            "1395 - 0.0\n",
            "1396 - 0.0\n",
            "1397 - 0.0\n",
            "1398 - 0.0\n",
            "1399 - 0.0\n",
            "1400 - 0.0\n",
            "1401 - 0.0\n",
            "1402 - 0.0\n",
            "1403 - 0.0\n",
            "1404 - 0.0\n",
            "1405 - 0.0\n",
            "1406 - 0.0\n",
            "1407 - 0.0\n",
            "1408 - 0.0\n",
            "1409 - 0.0\n",
            "1410 - 0.0\n",
            "1411 - 0.0\n",
            "1412 - 0.0\n",
            "1413 - 0.0\n",
            "1414 - 0.0\n",
            "1415 - 0.0\n",
            "1416 - 0.0\n",
            "1417 - 0.0\n",
            "1418 - 0.0\n",
            "1419 - 0.0\n",
            "1420 - 0.0\n",
            "1421 - 0.0\n",
            "1422 - 0.0\n",
            "1423 - 0.0\n",
            "1424 - 0.0\n",
            "1425 - 0.0\n",
            "1426 - 0.0\n",
            "1427 - 0.0\n",
            "1428 - 0.0\n",
            "1429 - 0.0\n",
            "1430 - 0.0\n",
            "1431 - 0.0\n",
            "1432 - 0.0\n",
            "1433 - 0.0\n",
            "1434 - 0.0\n",
            "1435 - 0.0\n",
            "1436 - 0.0\n",
            "1437 - 0.0\n",
            "1438 - 0.0\n",
            "1439 - 0.0\n",
            "1440 - 0.0\n",
            "1441 - 0.0\n",
            "1442 - 0.0\n",
            "1443 - 0.0\n",
            "1444 - 0.0\n",
            "1445 - 0.0\n",
            "1446 - 0.0\n",
            "1447 - 0.0\n",
            "1448 - 0.0\n",
            "1449 - 0.0\n",
            "1450 - 0.0\n",
            "1451 - 0.0\n",
            "1452 - 0.0\n",
            "1453 - 0.0\n",
            "1454 - 0.0\n",
            "1455 - 0.0\n",
            "1456 - 0.0\n",
            "1457 - 0.0\n",
            "1458 - 0.0\n",
            "1459 - 0.0\n",
            "1460 - 0.0\n",
            "1461 - 0.0\n",
            "1462 - 0.0\n",
            "1463 - 0.0\n",
            "1464 - 0.0\n",
            "1465 - 0.0\n",
            "1466 - 0.0\n",
            "1467 - 0.0\n",
            "1468 - 0.0\n",
            "1469 - 0.0\n",
            "1470 - 0.0\n",
            "1471 - 0.0\n",
            "1472 - 0.0\n",
            "1473 - 0.0\n",
            "1474 - 0.0\n",
            "1475 - 0.0\n",
            "1476 - 0.0\n",
            "1477 - 0.0\n",
            "1478 - 0.0\n",
            "1479 - 0.0\n",
            "1480 - 0.0\n",
            "1481 - 0.0\n",
            "1482 - 0.0\n",
            "1483 - 0.0\n",
            "1484 - 0.0\n",
            "1485 - 0.0\n",
            "1486 - 0.0\n",
            "1487 - 0.0\n",
            "1488 - 0.0\n",
            "1489 - 0.0\n",
            "1490 - 0.0\n",
            "1491 - 0.0\n",
            "1492 - 0.0\n",
            "1493 - 0.0\n",
            "1494 - 0.0\n",
            "1495 - 0.0\n",
            "1496 - 0.0\n",
            "1497 - 0.0\n",
            "1498 - 0.0\n",
            "1499 - 0.0\n",
            "1500 - 0.0\n",
            "1501 - 0.0\n",
            "1502 - 0.0\n",
            "1503 - 0.0\n",
            "1504 - 0.0\n",
            "1505 - 0.0\n",
            "1506 - 0.0\n",
            "1507 - 0.0\n",
            "1508 - 0.0\n",
            "1509 - 0.0\n",
            "1510 - 0.0\n",
            "1511 - 0.0\n",
            "1512 - 0.0\n",
            "1513 - 0.0\n",
            "1514 - 0.0\n",
            "1515 - 0.0\n",
            "1516 - 0.0\n",
            "1517 - 0.0\n",
            "1518 - 0.0\n",
            "1519 - 0.0\n",
            "1520 - 0.0\n",
            "1521 - 0.0\n",
            "1522 - 0.0\n",
            "1523 - 0.0\n",
            "1524 - 0.0\n",
            "1525 - 0.0\n",
            "1526 - 0.0\n",
            "1527 - 0.0\n",
            "1528 - 0.0\n",
            "1529 - 0.0\n",
            "1530 - 0.0\n",
            "1531 - 0.0\n",
            "1532 - 0.0\n",
            "1533 - 0.0\n",
            "1534 - 0.0\n",
            "1535 - 0.0\n",
            "1536 - 0.0\n",
            "1537 - 0.0\n",
            "1538 - 0.0\n",
            "1539 - 0.0\n",
            "1540 - 0.0\n",
            "1541 - 0.0\n",
            "1542 - 0.0\n",
            "1543 - 0.0\n",
            "1544 - 0.0\n",
            "1545 - 0.0\n",
            "1546 - 0.0\n",
            "1547 - 0.0\n",
            "1548 - 0.0\n",
            "1549 - 0.0\n",
            "1550 - 0.0\n",
            "1551 - 0.0\n",
            "1552 - 0.0\n",
            "1553 - 0.0\n",
            "1554 - 0.0\n",
            "1555 - 0.0\n",
            "1556 - 0.0\n",
            "1557 - 0.0\n",
            "1558 - 0.0\n",
            "1559 - 0.0\n",
            "1560 - 0.0\n",
            "1561 - 0.0\n",
            "1562 - 0.0\n",
            "1563 - 0.0\n",
            "1564 - 0.0\n",
            "1565 - 0.0\n",
            "1566 - 0.0\n",
            "1567 - 0.0\n",
            "1568 - 0.0\n",
            "1569 - 0.0\n",
            "1570 - 0.0\n",
            "1571 - 0.0\n",
            "1572 - 0.0\n",
            "1573 - 0.0\n",
            "1574 - 0.0\n",
            "1575 - 0.0\n",
            "1576 - 0.0\n",
            "1577 - 0.0\n",
            "1578 - 0.0\n",
            "1579 - 0.0\n",
            "1580 - 0.0\n",
            "1581 - 0.0\n",
            "1582 - 0.0\n",
            "1583 - 0.0\n",
            "1584 - 0.0\n",
            "1585 - 0.0\n",
            "1586 - 0.0\n",
            "1587 - 0.0\n",
            "1588 - 0.0\n",
            "1589 - 0.0\n",
            "1590 - 0.0\n",
            "1591 - 0.0\n",
            "1592 - 0.0\n",
            "1593 - 0.0\n",
            "1594 - 0.0\n",
            "1595 - 0.0\n",
            "1596 - 0.0\n",
            "1597 - 0.0\n",
            "1598 - 0.0\n",
            "1599 - 0.0\n",
            "1600 - 0.0\n",
            "1601 - 0.0\n",
            "1602 - 0.0\n",
            "1603 - 0.0\n",
            "1604 - 0.0\n",
            "1605 - 0.0\n",
            "1606 - 0.0\n",
            "1607 - 0.0\n",
            "1608 - 0.0\n",
            "1609 - 0.0\n",
            "1610 - 0.0\n",
            "1611 - 0.0\n",
            "1612 - 0.0\n",
            "1613 - 0.0\n",
            "1614 - 0.0\n",
            "1615 - 0.0\n",
            "1616 - 0.0\n",
            "1617 - 0.0\n",
            "1618 - 0.0\n",
            "1619 - 0.0\n",
            "1620 - 0.0\n",
            "1621 - 0.0\n",
            "1622 - 0.0\n",
            "1623 - 0.0\n",
            "1624 - 0.0\n",
            "1625 - 0.0\n",
            "1626 - 0.0\n",
            "1627 - 0.0\n",
            "1628 - 0.0\n",
            "1629 - 0.0\n",
            "1630 - 0.0\n",
            "1631 - 0.0\n",
            "1632 - 0.0\n",
            "1633 - 0.0\n",
            "1634 - 0.0\n",
            "1635 - 0.0\n",
            "1636 - 0.0\n",
            "1637 - 0.0\n",
            "1638 - 0.0\n",
            "1639 - 0.0\n",
            "1640 - 1.0\n",
            "1641 - 0.0\n",
            "1642 - 0.0\n",
            "1643 - 0.0\n",
            "1644 - 0.0\n",
            "1645 - 0.0\n",
            "1646 - 0.0\n",
            "1647 - 0.0\n",
            "1648 - 0.0\n",
            "1649 - 0.0\n",
            "1650 - 0.0\n",
            "1651 - 0.0\n",
            "1652 - 0.0\n",
            "1653 - 0.0\n",
            "1654 - 0.0\n",
            "1655 - 0.0\n",
            "1656 - 0.0\n",
            "1657 - 0.0\n",
            "1658 - 0.0\n",
            "1659 - 0.0\n",
            "1660 - 0.0\n",
            "1661 - 0.0\n",
            "1662 - 0.0\n",
            "1663 - 0.0\n",
            "1664 - 0.0\n",
            "1665 - 0.0\n",
            "1666 - 0.0\n",
            "1667 - 0.0\n",
            "1668 - 0.0\n",
            "1669 - 0.0\n",
            "1670 - 0.0\n",
            "1671 - 0.0\n",
            "1672 - 0.0\n",
            "1673 - 0.0\n",
            "1674 - 0.0\n",
            "1675 - 0.0\n",
            "1676 - 0.0\n",
            "1677 - 0.0\n",
            "1678 - 0.0\n",
            "1679 - 0.0\n",
            "1680 - 0.0\n",
            "1681 - 0.0\n",
            "1682 - 0.0\n",
            "1683 - 0.0\n",
            "1684 - 0.0\n",
            "1685 - 0.0\n",
            "1686 - 0.0\n",
            "1687 - 0.0\n",
            "1688 - 0.0\n",
            "1689 - 0.0\n",
            "1690 - 0.0\n",
            "1691 - 0.0\n",
            "1692 - 0.0\n",
            "1693 - 0.0\n",
            "1694 - 0.0\n",
            "1695 - 0.0\n",
            "1696 - 0.0\n",
            "1697 - 0.0\n",
            "1698 - 0.0\n",
            "1699 - 0.0\n",
            "1700 - 0.0\n",
            "1701 - 0.0\n",
            "1702 - 0.0\n",
            "1703 - 0.0\n",
            "1704 - 0.0\n",
            "1705 - 0.0\n",
            "1706 - 0.0\n",
            "1707 - 0.0\n",
            "1708 - 0.0\n",
            "1709 - 0.0\n",
            "1710 - 0.0\n",
            "1711 - 0.0\n",
            "1712 - 0.0\n",
            "1713 - 0.0\n",
            "1714 - 0.0\n",
            "1715 - 0.0\n",
            "1716 - 0.0\n",
            "1717 - 0.0\n",
            "1718 - 0.0\n",
            "1719 - 0.0\n",
            "1720 - 0.0\n",
            "1721 - 0.0\n",
            "1722 - 0.0\n",
            "1723 - 0.0\n",
            "1724 - 0.0\n",
            "1725 - 0.0\n",
            "1726 - 0.0\n",
            "1727 - 0.0\n",
            "1728 - 0.0\n",
            "1729 - 0.0\n",
            "1730 - 0.0\n",
            "1731 - 0.0\n",
            "1732 - 0.0\n",
            "1733 - 0.0\n",
            "1734 - 0.0\n",
            "1735 - 0.0\n",
            "1736 - 0.0\n",
            "1737 - 0.0\n",
            "1738 - 0.0\n",
            "1739 - 0.0\n",
            "1740 - 0.0\n",
            "1741 - 0.0\n",
            "1742 - 0.0\n",
            "1743 - 0.0\n",
            "1744 - 0.0\n",
            "1745 - 0.0\n",
            "1746 - 0.0\n",
            "1747 - 0.0\n",
            "1748 - 0.0\n",
            "1749 - 0.0\n",
            "1750 - 0.0\n",
            "1751 - 0.0\n",
            "1752 - 0.0\n",
            "1753 - 0.0\n",
            "1754 - 0.0\n",
            "1755 - 0.0\n",
            "1756 - 0.0\n",
            "1757 - 0.0\n",
            "1758 - 0.0\n",
            "1759 - 0.0\n",
            "1760 - 0.0\n",
            "1761 - 0.0\n",
            "1762 - 0.0\n",
            "1763 - 0.0\n",
            "1764 - 0.0\n",
            "1765 - 0.0\n",
            "1766 - 0.0\n",
            "1767 - 0.0\n",
            "1768 - 0.0\n",
            "1769 - 0.0\n",
            "1770 - 0.0\n",
            "1771 - 0.0\n",
            "1772 - 0.0\n",
            "1773 - 0.0\n",
            "1774 - 0.0\n",
            "1775 - 0.0\n",
            "1776 - 0.0\n",
            "1777 - 0.0\n",
            "1778 - 0.0\n",
            "1779 - 0.0\n",
            "1780 - 0.0\n",
            "1781 - 0.0\n",
            "1782 - 0.0\n",
            "1783 - 0.0\n",
            "1784 - 0.0\n",
            "1785 - 0.0\n",
            "1786 - 0.0\n",
            "1787 - 0.0\n",
            "1788 - 0.0\n",
            "1789 - 0.0\n",
            "1790 - 0.0\n",
            "1791 - 0.0\n",
            "1792 - 0.0\n",
            "1793 - 0.0\n",
            "1794 - 0.0\n",
            "1795 - 0.0\n",
            "1796 - 0.0\n",
            "1797 - 0.0\n",
            "1798 - 0.0\n",
            "1799 - 0.0\n",
            "1800 - 0.0\n",
            "1801 - 0.0\n",
            "1802 - 0.0\n",
            "1803 - 0.0\n",
            "1804 - 0.0\n",
            "1805 - 0.0\n",
            "1806 - 0.0\n",
            "1807 - 0.0\n",
            "1808 - 0.0\n",
            "1809 - 0.0\n",
            "1810 - 0.0\n",
            "1811 - 0.0\n",
            "1812 - 0.0\n",
            "1813 - 0.0\n",
            "1814 - 0.0\n",
            "1815 - 0.0\n",
            "1816 - 0.0\n",
            "1817 - 0.0\n",
            "1818 - 0.0\n",
            "1819 - 0.0\n",
            "1820 - 0.0\n",
            "1821 - 0.0\n",
            "1822 - 0.0\n",
            "1823 - 0.0\n",
            "1824 - 0.0\n",
            "1825 - 0.0\n",
            "1826 - 0.0\n",
            "1827 - 0.0\n",
            "1828 - 0.0\n",
            "1829 - 0.0\n",
            "1830 - 0.0\n",
            "1831 - 0.0\n",
            "1832 - 0.0\n",
            "1833 - 0.0\n",
            "1834 - 0.0\n",
            "1835 - 0.0\n",
            "1836 - 0.0\n",
            "1837 - 0.0\n",
            "1838 - 0.0\n",
            "1839 - 0.0\n",
            "1840 - 0.0\n",
            "1841 - 0.0\n",
            "1842 - 0.0\n",
            "1843 - 0.0\n",
            "1844 - 0.0\n",
            "1845 - 0.0\n",
            "1846 - 0.0\n",
            "1847 - 0.0\n",
            "1848 - 0.0\n",
            "1849 - 0.0\n",
            "1850 - 0.0\n",
            "1851 - 0.0\n",
            "1852 - 0.0\n",
            "1853 - 0.0\n",
            "1854 - 0.0\n",
            "1855 - 0.0\n",
            "1856 - 0.0\n",
            "1857 - 0.0\n",
            "1858 - 0.0\n",
            "1859 - 0.0\n",
            "1860 - 0.0\n",
            "1861 - 0.0\n",
            "1862 - 0.0\n",
            "1863 - 0.0\n",
            "1864 - 0.0\n",
            "1865 - 0.0\n",
            "1866 - 0.0\n",
            "1867 - 0.0\n",
            "1868 - 0.0\n",
            "1869 - 0.0\n",
            "1870 - 0.0\n",
            "1871 - 0.0\n",
            "1872 - 0.0\n",
            "1873 - 0.0\n",
            "1874 - 0.0\n",
            "1875 - 0.0\n",
            "1876 - 0.0\n",
            "1877 - 0.0\n",
            "1878 - 0.0\n",
            "1879 - 0.0\n",
            "1880 - 0.0\n",
            "1881 - 0.0\n",
            "1882 - 0.0\n",
            "1883 - 0.0\n",
            "1884 - 0.0\n",
            "1885 - 0.0\n",
            "1886 - 0.0\n",
            "1887 - 0.0\n",
            "1888 - 0.0\n",
            "1889 - 0.0\n",
            "1890 - 0.0\n",
            "1891 - 0.0\n",
            "1892 - 0.0\n",
            "1893 - 0.0\n",
            "1894 - 0.0\n",
            "1895 - 0.0\n",
            "1896 - 0.0\n",
            "1897 - 0.0\n",
            "1898 - 0.0\n",
            "1899 - 0.0\n",
            "1900 - 0.0\n",
            "1901 - 0.0\n",
            "1902 - 0.0\n",
            "1903 - 0.0\n",
            "1904 - 0.0\n",
            "1905 - 0.0\n",
            "1906 - 0.0\n",
            "1907 - 0.0\n",
            "1908 - 0.0\n",
            "1909 - 0.0\n",
            "1910 - 0.0\n",
            "1911 - 0.0\n",
            "1912 - 0.0\n",
            "1913 - 0.0\n",
            "1914 - 0.0\n",
            "1915 - 0.0\n",
            "1916 - 0.0\n",
            "1917 - 0.0\n",
            "1918 - 0.0\n",
            "1919 - 0.0\n",
            "1920 - 0.0\n",
            "1921 - 0.0\n",
            "1922 - 0.0\n",
            "1923 - 0.0\n",
            "1924 - 0.0\n",
            "1925 - 0.0\n",
            "1926 - 0.0\n",
            "1927 - 0.0\n",
            "1928 - 0.0\n",
            "1929 - 0.0\n",
            "1930 - 0.0\n",
            "1931 - 0.0\n",
            "1932 - 0.0\n",
            "1933 - 0.0\n",
            "1934 - 0.0\n",
            "1935 - 0.0\n",
            "1936 - 0.0\n",
            "1937 - 0.0\n",
            "1938 - 0.0\n",
            "1939 - 0.0\n",
            "1940 - 0.0\n",
            "1941 - 0.0\n",
            "1942 - 0.0\n",
            "1943 - 0.0\n",
            "1944 - 0.0\n",
            "1945 - 0.0\n",
            "1946 - 0.0\n",
            "1947 - 0.0\n",
            "1948 - 0.0\n",
            "1949 - 0.0\n",
            "1950 - 0.0\n",
            "1951 - 0.0\n",
            "1952 - 0.0\n",
            "1953 - 0.0\n",
            "1954 - 0.0\n",
            "1955 - 0.0\n",
            "1956 - 0.0\n",
            "1957 - 0.0\n",
            "1958 - 0.0\n",
            "1959 - 0.0\n",
            "1960 - 0.0\n",
            "1961 - 0.0\n",
            "1962 - 0.0\n",
            "1963 - 0.0\n",
            "1964 - 0.0\n",
            "1965 - 0.0\n",
            "1966 - 0.0\n",
            "1967 - 0.0\n",
            "1968 - 0.0\n",
            "1969 - 0.0\n",
            "1970 - 0.0\n",
            "1971 - 0.0\n",
            "1972 - 0.0\n",
            "1973 - 0.0\n",
            "1974 - 1.0\n",
            "1975 - 1.0\n",
            "1976 - 1.0\n",
            "1977 - 0.0\n",
            "1978 - 0.0\n",
            "1979 - 0.0\n",
            "1980 - 0.0\n",
            "1981 - 0.0\n",
            "1982 - 0.0\n",
            "1983 - 0.0\n",
            "1984 - 0.0\n",
            "1985 - 0.0\n",
            "1986 - 0.0\n",
            "1987 - 0.0\n",
            "1988 - 0.0\n",
            "1989 - 0.0\n",
            "1990 - 0.0\n",
            "1991 - 0.0\n",
            "1992 - 0.0\n",
            "1993 - 0.0\n",
            "1994 - 0.0\n",
            "1995 - 0.0\n",
            "1996 - 0.0\n",
            "1997 - 0.0\n",
            "1998 - 0.0\n",
            "1999 - 0.0\n",
            "2000 - 0.0\n",
            "2001 - 0.0\n",
            "2002 - 0.0\n",
            "2003 - 0.0\n",
            "2004 - 0.0\n",
            "2005 - 0.0\n",
            "2006 - 0.0\n",
            "2007 - 0.0\n",
            "2008 - 0.0\n",
            "2009 - 0.0\n",
            "2010 - 0.0\n",
            "2011 - 0.0\n",
            "2012 - 0.0\n",
            "2013 - 0.0\n",
            "2014 - 0.0\n",
            "2015 - 0.0\n",
            "2016 - 0.0\n",
            "2017 - 0.0\n",
            "2018 - 0.0\n",
            "2019 - 0.0\n",
            "2020 - 0.0\n",
            "2021 - 0.0\n",
            "2022 - 0.0\n",
            "2023 - 0.0\n",
            "2024 - 0.0\n",
            "2025 - 0.0\n",
            "2026 - 0.0\n",
            "2027 - 0.0\n",
            "2028 - 0.0\n",
            "2029 - 0.0\n",
            "2030 - 0.0\n",
            "2031 - 0.0\n",
            "2032 - 0.0\n",
            "2033 - 0.0\n",
            "2034 - 0.0\n",
            "2035 - 0.0\n",
            "2036 - 0.0\n",
            "2037 - 0.0\n",
            "2038 - 0.0\n",
            "2039 - 0.0\n",
            "2040 - 0.0\n",
            "2041 - 0.0\n",
            "2042 - 0.0\n",
            "2043 - 0.0\n",
            "2044 - 0.0\n",
            "2045 - 0.0\n",
            "2046 - 0.0\n",
            "2047 - 0.0\n",
            "2048 - 0.0\n",
            "2049 - 0.0\n",
            "2050 - 0.0\n",
            "2051 - 0.0\n",
            "2052 - 0.0\n",
            "2053 - 0.0\n",
            "2054 - 0.0\n",
            "2055 - 0.0\n",
            "2056 - 0.0\n",
            "2057 - 0.0\n",
            "2058 - 0.0\n",
            "2059 - 0.0\n",
            "2060 - 0.0\n",
            "2061 - 0.0\n",
            "2062 - 0.0\n",
            "2063 - 0.0\n",
            "2064 - 0.0\n",
            "2065 - 0.0\n",
            "2066 - 0.0\n",
            "2067 - 0.0\n",
            "2068 - 0.0\n",
            "2069 - 0.0\n",
            "2070 - 0.0\n",
            "2071 - 0.0\n",
            "2072 - 0.0\n",
            "2073 - 0.0\n",
            "2074 - 0.0\n",
            "2075 - 0.0\n",
            "2076 - 0.0\n",
            "2077 - 0.0\n",
            "2078 - 0.0\n",
            "2079 - 0.0\n",
            "2080 - 0.0\n",
            "2081 - 0.0\n",
            "2082 - 0.0\n",
            "2083 - 0.0\n",
            "2084 - 0.0\n",
            "2085 - 0.0\n",
            "2086 - 0.0\n",
            "2087 - 0.0\n",
            "2088 - 0.0\n",
            "2089 - 0.0\n",
            "2090 - 0.0\n",
            "2091 - 0.0\n",
            "2092 - 0.0\n",
            "2093 - 0.0\n",
            "2094 - 0.0\n",
            "2095 - 0.0\n",
            "2096 - 0.0\n",
            "2097 - 0.0\n",
            "2098 - 0.0\n",
            "2099 - 0.0\n",
            "2100 - 0.0\n",
            "2101 - 0.0\n",
            "2102 - 0.0\n",
            "2103 - 0.0\n",
            "2104 - 0.0\n",
            "2105 - 0.0\n",
            "2106 - 0.0\n",
            "2107 - 0.0\n",
            "2108 - 0.0\n",
            "2109 - 0.0\n",
            "2110 - 0.0\n",
            "2111 - 0.0\n",
            "2112 - 0.0\n",
            "2113 - 0.0\n",
            "2114 - 0.0\n",
            "2115 - 0.0\n",
            "2116 - 0.0\n",
            "2117 - 0.0\n",
            "2118 - 0.0\n",
            "2119 - 0.0\n",
            "2120 - 0.0\n",
            "2121 - 0.0\n",
            "2122 - 0.0\n",
            "2123 - 0.0\n",
            "2124 - 0.0\n",
            "2125 - 0.0\n",
            "2126 - 0.0\n",
            "2127 - 0.0\n",
            "2128 - 0.0\n",
            "2129 - 0.0\n",
            "2130 - 0.0\n",
            "2131 - 0.0\n",
            "2132 - 0.0\n",
            "2133 - 0.0\n",
            "2134 - 0.0\n",
            "2135 - 0.0\n",
            "2136 - 0.0\n",
            "2137 - 0.0\n",
            "2138 - 0.0\n",
            "2139 - 0.0\n",
            "2140 - 0.0\n",
            "2141 - 0.0\n",
            "2142 - 0.0\n",
            "2143 - 0.0\n",
            "2144 - 0.0\n",
            "2145 - 0.0\n",
            "2146 - 0.0\n",
            "2147 - 0.0\n",
            "2148 - 0.0\n",
            "2149 - 0.0\n",
            "2150 - 0.0\n",
            "2151 - 0.0\n",
            "2152 - 0.0\n",
            "2153 - 0.0\n",
            "2154 - 0.0\n",
            "2155 - 0.0\n",
            "2156 - 0.0\n",
            "2157 - 0.0\n",
            "2158 - 0.0\n",
            "2159 - 0.0\n",
            "2160 - 0.0\n",
            "2161 - 0.0\n",
            "2162 - 0.0\n",
            "2163 - 0.0\n",
            "2164 - 0.0\n",
            "2165 - 0.0\n",
            "2166 - 0.0\n",
            "2167 - 0.0\n",
            "2168 - 0.0\n",
            "2169 - 0.0\n",
            "2170 - 0.0\n",
            "2171 - 0.0\n",
            "2172 - 0.0\n",
            "2173 - 0.0\n",
            "2174 - 0.0\n",
            "2175 - 0.0\n",
            "2176 - 0.0\n",
            "2177 - 0.0\n",
            "2178 - 0.0\n",
            "2179 - 0.0\n",
            "2180 - 0.0\n",
            "2181 - 0.0\n",
            "2182 - 0.0\n",
            "2183 - 0.0\n",
            "2184 - 0.0\n",
            "2185 - 0.0\n",
            "2186 - 0.0\n",
            "2187 - 0.0\n",
            "2188 - 0.0\n",
            "2189 - 0.0\n",
            "2190 - 0.0\n",
            "2191 - 0.0\n",
            "2192 - 0.0\n",
            "2193 - 0.0\n",
            "2194 - 0.0\n",
            "2195 - 0.0\n",
            "2196 - 0.0\n",
            "2197 - 0.0\n",
            "2198 - 0.0\n",
            "2199 - 0.0\n",
            "2200 - 0.0\n",
            "2201 - 0.0\n",
            "2202 - 0.0\n",
            "2203 - 0.0\n",
            "2204 - 0.0\n",
            "2205 - 0.0\n",
            "2206 - 0.0\n",
            "2207 - 0.0\n",
            "2208 - 0.0\n",
            "2209 - 0.0\n",
            "2210 - 0.0\n",
            "2211 - 0.0\n",
            "2212 - 0.0\n",
            "2213 - 0.0\n",
            "2214 - 0.0\n",
            "2215 - 0.0\n",
            "2216 - 0.0\n",
            "2217 - 0.0\n",
            "2218 - 0.0\n",
            "2219 - 0.0\n",
            "2220 - 0.0\n",
            "2221 - 0.0\n",
            "2222 - 0.0\n",
            "2223 - 0.0\n",
            "2224 - 0.0\n",
            "2225 - 0.0\n",
            "2226 - 0.0\n",
            "2227 - 0.0\n",
            "2228 - 0.0\n",
            "2229 - 0.0\n",
            "2230 - 0.0\n",
            "2231 - 0.0\n",
            "2232 - 0.0\n",
            "2233 - 0.0\n",
            "2234 - 0.0\n",
            "2235 - 0.0\n",
            "2236 - 0.0\n",
            "2237 - 0.0\n",
            "2238 - 0.0\n",
            "2239 - 0.0\n",
            "2240 - 0.0\n",
            "2241 - 0.0\n",
            "2242 - 0.0\n",
            "2243 - 0.0\n",
            "2244 - 0.0\n",
            "2245 - 0.0\n",
            "2246 - 0.0\n",
            "2247 - 0.0\n",
            "2248 - 0.0\n",
            "2249 - 0.0\n",
            "2250 - 0.0\n",
            "2251 - 0.0\n",
            "2252 - 0.0\n",
            "2253 - 0.0\n",
            "2254 - 0.0\n",
            "2255 - 0.0\n",
            "2256 - 0.0\n",
            "2257 - 0.0\n",
            "2258 - 0.0\n",
            "2259 - 0.0\n",
            "2260 - 0.0\n",
            "2261 - 0.0\n",
            "2262 - 0.0\n",
            "2263 - 0.0\n",
            "2264 - 0.0\n",
            "2265 - 0.0\n",
            "2266 - 0.0\n",
            "2267 - 0.0\n",
            "2268 - 0.0\n",
            "2269 - 0.0\n",
            "2270 - 0.0\n",
            "2271 - 0.0\n",
            "2272 - 0.0\n",
            "2273 - 0.0\n",
            "2274 - 0.0\n",
            "2275 - 0.0\n",
            "2276 - 0.0\n",
            "2277 - 0.0\n",
            "2278 - 0.0\n",
            "2279 - 0.0\n",
            "2280 - 0.0\n",
            "2281 - 0.0\n",
            "2282 - 0.0\n",
            "2283 - 0.0\n",
            "2284 - 0.0\n",
            "2285 - 0.0\n",
            "2286 - 0.0\n",
            "2287 - 0.0\n",
            "2288 - 0.0\n",
            "2289 - 0.0\n",
            "2290 - 0.0\n",
            "2291 - 0.0\n",
            "2292 - 0.0\n",
            "2293 - 0.0\n",
            "2294 - 0.0\n",
            "2295 - 0.0\n",
            "2296 - 0.0\n",
            "2297 - 0.0\n",
            "2298 - 0.0\n",
            "2299 - 0.0\n",
            "2300 - 0.0\n",
            "2301 - 0.0\n",
            "2302 - 0.0\n",
            "2303 - 0.0\n",
            "2304 - 0.0\n",
            "2305 - 0.0\n",
            "2306 - 0.0\n",
            "2307 - 0.0\n",
            "2308 - 0.0\n",
            "2309 - 0.0\n",
            "2310 - 0.0\n",
            "2311 - 0.0\n",
            "2312 - 0.0\n",
            "2313 - 0.0\n",
            "2314 - 0.0\n",
            "2315 - 0.0\n",
            "2316 - 0.0\n",
            "2317 - 0.0\n",
            "2318 - 0.0\n",
            "2319 - 0.0\n",
            "2320 - 0.0\n",
            "2321 - 0.0\n",
            "2322 - 0.0\n",
            "2323 - 0.0\n",
            "2324 - 0.0\n",
            "2325 - 0.0\n",
            "2326 - 0.0\n",
            "2327 - 0.0\n",
            "2328 - 0.0\n",
            "2329 - 0.0\n",
            "2330 - 0.0\n",
            "2331 - 0.0\n",
            "2332 - 0.0\n",
            "2333 - 0.0\n",
            "2334 - 0.0\n",
            "2335 - 0.0\n",
            "2336 - 0.0\n",
            "2337 - 0.0\n",
            "2338 - 0.0\n",
            "2339 - 0.0\n",
            "2340 - 0.0\n",
            "2341 - 0.0\n",
            "2342 - 0.0\n",
            "2343 - 0.0\n",
            "2344 - 0.0\n",
            "2345 - 0.0\n",
            "2346 - 0.0\n",
            "2347 - 0.0\n",
            "2348 - 0.0\n",
            "2349 - 0.0\n",
            "2350 - 0.0\n",
            "2351 - 0.0\n",
            "2352 - 0.0\n",
            "2353 - 0.0\n",
            "2354 - 0.0\n",
            "2355 - 0.0\n",
            "2356 - 0.0\n",
            "2357 - 0.0\n",
            "2358 - 0.0\n",
            "2359 - 0.0\n",
            "2360 - 0.0\n",
            "2361 - 0.0\n",
            "2362 - 0.0\n",
            "2363 - 0.0\n",
            "2364 - 0.0\n",
            "2365 - 0.0\n",
            "2366 - 0.0\n",
            "2367 - 0.0\n",
            "2368 - 0.0\n",
            "2369 - 0.0\n",
            "2370 - 0.0\n",
            "2371 - 0.0\n",
            "2372 - 0.0\n",
            "2373 - 0.0\n",
            "2374 - 0.0\n",
            "2375 - 0.0\n",
            "2376 - 0.0\n",
            "2377 - 0.0\n",
            "2378 - 0.0\n",
            "2379 - 0.0\n",
            "2380 - 0.0\n",
            "2381 - 0.0\n",
            "2382 - 0.0\n",
            "2383 - 0.0\n",
            "2384 - 0.0\n",
            "2385 - 0.0\n",
            "2386 - 0.0\n",
            "2387 - 0.0\n",
            "2388 - 0.0\n",
            "2389 - 0.0\n",
            "2390 - 0.0\n",
            "2391 - 0.0\n",
            "2392 - 0.0\n",
            "2393 - 0.0\n",
            "2394 - 0.0\n",
            "2395 - 0.0\n",
            "2396 - 0.0\n",
            "2397 - 0.0\n",
            "2398 - 0.0\n",
            "2399 - 0.0\n",
            "2400 - 0.0\n",
            "2401 - 0.0\n",
            "2402 - 0.0\n",
            "2403 - 0.0\n",
            "2404 - 0.0\n",
            "2405 - 0.0\n",
            "2406 - 0.0\n",
            "2407 - 0.0\n",
            "2408 - 0.0\n",
            "2409 - 0.0\n",
            "2410 - 0.0\n",
            "2411 - 0.0\n",
            "2412 - 0.0\n",
            "2413 - 0.0\n",
            "2414 - 0.0\n",
            "2415 - 0.0\n",
            "2416 - 0.0\n",
            "2417 - 0.0\n",
            "2418 - 0.0\n",
            "2419 - 0.0\n",
            "2420 - 0.0\n",
            "2421 - 0.0\n",
            "2422 - 0.0\n",
            "2423 - 0.0\n",
            "2424 - 0.0\n",
            "2425 - 0.0\n",
            "2426 - 0.0\n",
            "2427 - 0.0\n",
            "2428 - 0.0\n",
            "2429 - 0.0\n",
            "2430 - 0.0\n",
            "2431 - 0.0\n",
            "2432 - 0.0\n",
            "2433 - 0.0\n",
            "2434 - 0.0\n",
            "2435 - 0.0\n",
            "2436 - 0.0\n",
            "2437 - 0.0\n",
            "2438 - 0.0\n",
            "2439 - 0.0\n",
            "2440 - 0.0\n",
            "2441 - 0.0\n",
            "2442 - 0.0\n",
            "2443 - 0.0\n",
            "2444 - 0.0\n",
            "2445 - 0.0\n",
            "2446 - 0.0\n",
            "2447 - 0.0\n",
            "2448 - 0.0\n",
            "2449 - 0.0\n",
            "2450 - 0.0\n",
            "2451 - 0.0\n",
            "2452 - 0.0\n",
            "2453 - 0.0\n",
            "2454 - 0.0\n",
            "2455 - 0.0\n",
            "2456 - 0.0\n",
            "2457 - 0.0\n",
            "2458 - 0.0\n",
            "2459 - 0.0\n",
            "2460 - 0.0\n",
            "2461 - 0.0\n",
            "2462 - 0.0\n",
            "2463 - 0.0\n",
            "2464 - 0.0\n",
            "2465 - 0.0\n",
            "2466 - 0.0\n",
            "2467 - 0.0\n",
            "2468 - 0.0\n",
            "2469 - 0.0\n",
            "2470 - 0.0\n",
            "2471 - 0.0\n",
            "2472 - 0.0\n",
            "2473 - 0.0\n",
            "2474 - 0.0\n",
            "2475 - 0.0\n",
            "2476 - 0.0\n",
            "2477 - 0.0\n",
            "2478 - 0.0\n",
            "2479 - 0.0\n",
            "2480 - 0.0\n",
            "2481 - 0.0\n",
            "2482 - 0.0\n",
            "2483 - 0.0\n",
            "2484 - 0.0\n",
            "2485 - 0.0\n",
            "2486 - 0.0\n",
            "2487 - 0.0\n",
            "2488 - 0.0\n",
            "2489 - 0.0\n",
            "2490 - 0.0\n",
            "2491 - 0.0\n",
            "2492 - 0.0\n",
            "2493 - 0.0\n",
            "2494 - 0.0\n",
            "2495 - 0.0\n",
            "2496 - 0.0\n",
            "2497 - 0.0\n",
            "2498 - 0.0\n",
            "2499 - 0.0\n",
            "2500 - 0.0\n",
            "2501 - 0.0\n",
            "2502 - 0.0\n",
            "2503 - 0.0\n",
            "2504 - 0.0\n",
            "2505 - 0.0\n",
            "2506 - 0.0\n",
            "2507 - 0.0\n",
            "2508 - 0.0\n",
            "2509 - 0.0\n",
            "2510 - 0.0\n",
            "2511 - 0.0\n",
            "2512 - 0.0\n",
            "2513 - 0.0\n",
            "2514 - 0.0\n",
            "2515 - 0.0\n",
            "2516 - 0.0\n",
            "2517 - 0.0\n",
            "2518 - 0.0\n",
            "2519 - 0.0\n",
            "2520 - 0.0\n",
            "2521 - 0.0\n",
            "2522 - 0.0\n",
            "2523 - 0.0\n",
            "2524 - 0.0\n",
            "2525 - 0.0\n",
            "2526 - 0.0\n",
            "2527 - 0.0\n",
            "2528 - 0.0\n",
            "2529 - 0.0\n",
            "2530 - 0.0\n",
            "2531 - 0.0\n",
            "2532 - 0.0\n",
            "2533 - 0.0\n",
            "2534 - 0.0\n",
            "2535 - 0.0\n",
            "2536 - 0.0\n",
            "2537 - 0.0\n",
            "2538 - 0.0\n",
            "2539 - 0.0\n",
            "2540 - 0.0\n",
            "2541 - 0.0\n",
            "2542 - 0.0\n",
            "2543 - 0.0\n",
            "2544 - 0.0\n",
            "2545 - 0.0\n",
            "2546 - 0.0\n",
            "2547 - 0.0\n",
            "2548 - 0.0\n",
            "2549 - 0.0\n",
            "2550 - 0.0\n",
            "2551 - 0.0\n",
            "2552 - 0.0\n",
            "2553 - 0.0\n",
            "2554 - 0.0\n",
            "2555 - 0.0\n",
            "2556 - 0.0\n",
            "2557 - 0.0\n",
            "2558 - 0.0\n",
            "2559 - 0.0\n",
            "2560 - 0.0\n",
            "2561 - 0.0\n",
            "2562 - 0.0\n",
            "2563 - 0.0\n",
            "2564 - 0.0\n",
            "2565 - 0.0\n",
            "2566 - 0.0\n",
            "2567 - 0.0\n",
            "2568 - 0.0\n",
            "2569 - 0.0\n",
            "2570 - 0.0\n",
            "2571 - 0.0\n",
            "2572 - 0.0\n",
            "2573 - 0.0\n",
            "2574 - 0.0\n",
            "2575 - 0.0\n",
            "2576 - 0.0\n",
            "2577 - 0.0\n",
            "2578 - 0.0\n",
            "2579 - 0.0\n",
            "2580 - 0.0\n",
            "2581 - 0.0\n",
            "2582 - 0.0\n",
            "2583 - 0.0\n",
            "2584 - 0.0\n",
            "2585 - 0.0\n",
            "2586 - 0.0\n",
            "2587 - 0.0\n",
            "2588 - 0.0\n",
            "2589 - 0.0\n",
            "2590 - 0.0\n",
            "2591 - 0.0\n",
            "2592 - 0.0\n",
            "2593 - 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKqZe2gzIzAx",
        "colab_type": "text"
      },
      "source": [
        "Neuronales Netz erzeugen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1O5JPACIzAy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "43bc26e6-25f7-422a-cb78-7c18c2509007"
      },
      "source": [
        "def build_model():\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Dense(layD, activation='tanh',\n",
        "                           input_shape=(sequences_laenge+1,)))\n",
        "    #model.add(layers.Dense(layD, activation='relu'))\n",
        "    model.add(layers.Dense(layD, activation='tanh')) \n",
        "    model.add(layers.Dense((1), activation='sigmoid'))\n",
        "    model.compile(optimizer='rmsprop', loss='mse', metrics=['binary_accuracy'])\n",
        "    return model"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMw8MRDZIzA5",
        "colab_type": "text"
      },
      "source": [
        "Neuronales Netz trainieren"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gSOLmWWIzA6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4005cf13-80a7-460d-ef7c-0ce896e02779"
      },
      "source": [
        "k = k_fach\n",
        "num_val_samples = len(x_train) // k \n",
        "num_epochs = 4\n",
        "all_scores = []\n",
        "for i in range(k):\n",
        "    print('processing fold #', i)\n",
        "    # Prepare the validation data: data from partition # k\n",
        "    val_data = x_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "    val_targets = y_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "\n",
        "    # Prepare the training data: data from all other partitions\n",
        "    partial_x_train = np.concatenate(\n",
        "        [x_train[:i * num_val_samples],\n",
        "         x_train[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "    partial_y_train = np.concatenate(\n",
        "        [y_train[:i * num_val_samples],\n",
        "         y_train[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "\n",
        "    # Build the Keras model (already compiled)\n",
        "    model = build_model()\n",
        "    # Train the model (in silent mode, verbose=0)\n",
        "    model.fit(partial_x_train, partial_y_train,\n",
        "              epochs=num_epochs, batch_size = 8, verbose=0)\n",
        "    # Evaluate the model on the validation data\n",
        "    val_mse, val_binary_accuracy = model.evaluate(val_data, val_targets, verbose=0)\n",
        "    all_scores.append(val_binary_accuracy)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "processing fold # 0\n",
            "processing fold # 1\n",
            "processing fold # 2\n",
            "processing fold # 3\n",
            "processing fold # 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdMZNVSqIzA9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "8aa0d09c-337d-471e-e935-6800d86ef44e"
      },
      "source": [
        "all_scores"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9452054500579834,\n",
              " 0.9589040875434875,\n",
              " 0.9452054500579834,\n",
              " 0.9726027250289917,\n",
              " 0.9726027250289917]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWPNjb0CIzBA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b1d7f5fd-1643-4155-fa1f-51323e3264c4"
      },
      "source": [
        "np.mean(all_scores)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9589040875434875"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQZielyXIzBE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "11f9b8e8-66fd-4483-ce35-74a1af53ceb0"
      },
      "source": [
        "num_epochs = 8\n",
        "all_binary_accuracy_histories = []\n",
        "for i in range(k):\n",
        "    print('processing fold #', i)\n",
        "    # Prepare the validation data: data from partition # k\n",
        "    val_data = x_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "    val_targets = y_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "\n",
        "    # Prepare the training data: data from all other partitions\n",
        "    partial_x_train = np.concatenate(\n",
        "        [x_train[:i * num_val_samples],\n",
        "         x_train[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "    partial_y_train = np.concatenate(\n",
        "        [y_train[:i * num_val_samples],\n",
        "         y_train[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "\n",
        "    # Build the Keras model (already compiled)\n",
        "    model = build_model()\n",
        "    # Train the model (in silent mode, verbose=0)\n",
        "    history = model.fit(partial_x_train, partial_y_train,\n",
        "                        validation_data=(val_data, val_targets),\n",
        "                        epochs=num_epochs, batch_size = 8, verbose=0)\n",
        "    binary_accuracy_history = history.history['val_binary_accuracy']\n",
        "    all_binary_accuracy_histories.append(binary_accuracy_history)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "processing fold # 0\n",
            "processing fold # 1\n",
            "processing fold # 2\n",
            "processing fold # 3\n",
            "processing fold # 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKEf_aq8IzBG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "5b45d73e-70c0-43f8-fc04-cfa5f946e5f9"
      },
      "source": [
        "average_binary_accuracy_history = [\n",
        "    np.mean([x[i] for x in all_binary_accuracy_histories]) for i in range(num_epochs)]\n",
        "for i, element in enumerate(average_binary_accuracy_history):\n",
        "    print(i,'-', element)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0 - 0.9260273933410644\n",
            "1 - 0.9616438269615173\n",
            "2 - 0.9643835425376892\n",
            "3 - 0.9589040994644165\n",
            "4 - 0.9589040994644165\n",
            "5 - 0.9589040994644165\n",
            "6 - 0.9589040994644165\n",
            "7 - 0.9589040994644165\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmLZfUpdIzBJ",
        "colab_type": "text"
      },
      "source": [
        "## Messdaten erstellen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGdaNQk3IzBK",
        "colab_type": "text"
      },
      "source": [
        "!!! Den gesuchten Typ bestimmen !!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6uA0EQMIzBK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1189fda0-f7c7-4ab5-ae98-38a8b9ef0c27"
      },
      "source": [
        "typNum =''\n",
        "episode_string_mess = \"gesamt_string_mess.csv\"\n",
        "episode_roh_mess = \"gesamt_roh_mess.csv\"\n",
        "episode_binar_mess = \"gesamt_binar_mess.csv\""
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z09cljveIzBP",
        "colab_type": "text"
      },
      "source": [
        "Alte Datei mit gleichem Namen löschen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Wl283dbIzBP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3b4e1038-fd84-490a-b45d-349099400504"
      },
      "source": [
        "import os\n",
        "if os.path.exists(episode_string_mess):\n",
        "    os.remove(episode_string_mess)\n",
        "else:\n",
        "    print(\"Diese Datei existiert nicht\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5HBDOVSIzBS",
        "colab_type": "text"
      },
      "source": [
        "Nach den entsprechenden Textdateien im Ordnet suchen und in einer rohe Datei zusammentragen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnPcck42IzBT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e779f568-7c3f-4b1e-9d54-52e93c3204cc"
      },
      "source": [
        "import glob\n",
        "\n",
        "def word_to_lex(word):\n",
        "    ret=(word) \n",
        "    return ret\n",
        "\n",
        "def write_back(words):\n",
        "    with open(episode_roh_mess,\"a\", encoding='utf-8') as output:\n",
        "        for word in words:\n",
        "            #print(word)\n",
        "            as_lex = word_to_lex(word[0])\n",
        "            full_word = '\"' + as_lex + '\"'\n",
        "            for sub_word in word[1:]:\n",
        "                full_word += \" , \"  '\"' + sub_word + '\"'\n",
        "            full_word +=\"\\n\"\n",
        "            output.write(full_word)\n",
        "\n",
        "def clean(line):\n",
        "    line = line.replace(\"\\n\",\" \").strip().lower()\n",
        "    line = line.replace(\"ä\",\"ae\").replace(\"ü\",\"ue\").replace(\"ö\",\"oe\").replace(\"ß\",\"ss\").replace(\",\",\"\").replace(\"«\",\"\")\n",
        "    line = line.replace(\"»\",\"\").replace(\".\",\"\").replace(\":\",\"\").replace(\";\",\"\").replace('\"',\"\")\n",
        "    line = line.replace(\"?\",\"\").replace(\"!\",\"\").replace(\"á\",\"a\").replace(\",\",\"\").replace(\"\\t\",\" \").replace(\"'\",\"\")\n",
        "    line = line.replace(\"‹\",\"\").replace(\"›\",\"\").replace(\"-\",\" \").replace(\"'('\",\"\").replace(\"')'\",\"\").replace('>','')\n",
        "    line = line.replace(\"    \",\" \").replace(\"   \",\" \").replace(\"  \",\" \").replace('–','').replace('—','').replace('<','')\n",
        "    line = line.replace(\"Â\", \"A\").replace(\"ø\", \"oe\").replace('“','').replace('„','').replace('(','').replace(')','')\n",
        "    line = line.replace(\"‚\", \"\").replace(']','').replace('[','')\n",
        "    if line == \"\": \n",
        "        return\n",
        "    \n",
        "    line=line.split(\"|\")\n",
        "    line[0]=line[0].split(\"|\")[0]\n",
        "    flex=[]\n",
        "    try:\n",
        "        flex=line[1].split(\"\")\n",
        "    except:\n",
        "        pass\n",
        "    value=str(line)\n",
        "    line=str(line)   \n",
        "    flex.append(line)\n",
        "    ret=[]\n",
        "    for i in flex:\n",
        "        ret.append((i,value[0]))\n",
        "    return ret\n",
        "\n",
        "with open(episode_roh_mess, \"w\", encoding='utf-8') as output:\n",
        "    output.write (\"quelle,episode,index_string,index_binar\\n\")\n",
        "pairs = []\n",
        "\n",
        "for file in glob.glob(\"Messdaten/*.txt\"):\n",
        "    if typNum in file:\n",
        "        with open(file, 'r', encoding='utf-8') as episode:\n",
        "            for line in episode.readlines():\n",
        "                clean_words = clean(line)\n",
        "                pairs = pairs + clean_words\n",
        "write_back(pairs)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6u0nnCMIzBW",
        "colab_type": "text"
      },
      "source": [
        "Rohdatei endgültig überarbeiten und in eine CSV Datei speichern"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwAYPYZsIzBW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "be6df6fa-e71b-42fb-ba0a-381c9d444a70"
      },
      "source": [
        "fin = open(episode_roh_mess,'r', encoding ='utf-8')\n",
        "fout = open(episode_string_mess, \"wt\", encoding ='utf-8')\n",
        "for kfz in fin:\n",
        "    fout.write(kfz.replace(', \"[\"',\"\").replace('\"[', \"\").replace(']\"',\"\").replace(\"', '\", \"','\").replace(\" '\", \"'\"))                      \n",
        "fin.close()\n",
        "fout.close()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HTiMU58IzBb",
        "colab_type": "text"
      },
      "source": [
        "Die in der CSV Datei etikettierte Episoden auflisten"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_HNTKIIIzBb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "40b1736d-4be4-4af9-b029-534c581cede2"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(episode_string_mess, encoding='utf-8')\n",
        "from collections import Counter\n",
        "indexliste=Counter(df.index_string)\n",
        "print(*indexliste, sep='\\n')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "'0'\n",
            "'e707_e_anfangssituation_erstes_treffen_bis_zur_schwangerschaft' \n",
            "'e707_g_abwesenheit_des_koenigs_bis_zur_bestrafung_der_koenigin'\n",
            "'e707_i_getrenntes_leben_bis_zur_anregung_fuer_die_wunderbare_dinge_oder_aufklaerung'\n",
            "'e707_k_setzen_der_vorletzten_herausforderung_aufgabe_des_ziels'\n",
            "'e707_m_begegnung_mit_dem_helfer'\n",
            "'e707_o_bei_der_erfuellung_der_vorletzten_herausforderung_aufgabe_des_ziels'\n",
            "'e707_s_die_letzte_begegnung_mit_dem_helfer'\n",
            "'e707_u_bei_der_erfuehlung_der_letzten_herausforderung_aufgabe_des_ziels'\n",
            "'e707_w_wiedervereinigung_der_familie_bis_zur_bestraffung_der_antagonisten/antagonistin'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5F_mQjb6IzBg",
        "colab_type": "text"
      },
      "source": [
        "Messdaten laden und aufbereiten"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XTbpoLhIzBh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "2c767754-b4c5-420d-9f18-95f4d6f259d4"
      },
      "source": [
        "fin = open(episode_string_mess,'r', encoding='utf-8') \n",
        "fout = open(episode_binar_mess, \"wt\", encoding='utf-8')\n",
        "for efz in fin:\n",
        "    fout.write(efz.replace(\"'\",\"\"))\n",
        "                                 \n",
        "fin.close()\n",
        "fout.close()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyF87dMWIzBk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f14bb20f-c0b7-4aa2-97f0-f93dc39069a4"
      },
      "source": [
        "df = pd.read_csv(episode_binar_mess, encoding='utf-8')\n",
        "indexliste=Counter(df.index_string)\n",
        "print(indexliste, sep='\\n')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Counter({'0': 147, 'e707_k_setzen_der_vorletzten_herausforderung_aufgabe_des_ziels': 2, 'e707_o_bei_der_erfuellung_der_vorletzten_herausforderung_aufgabe_des_ziels': 2, 'e707_e_anfangssituation_erstes_treffen_bis_zur_schwangerschaft ': 1, 'e707_g_abwesenheit_des_koenigs_bis_zur_bestrafung_der_koenigin': 1, 'e707_i_getrenntes_leben_bis_zur_anregung_fuer_die_wunderbare_dinge_oder_aufklaerung': 1, 'e707_m_begegnung_mit_dem_helfer': 1, 'e707_s_die_letzte_begegnung_mit_dem_helfer': 1, 'e707_u_bei_der_erfuehlung_der_letzten_herausforderung_aufgabe_des_ziels': 1, 'e707_w_wiedervereinigung_der_familie_bis_zur_bestraffung_der_antagonisten/antagonistin': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSRMrEb0IzBq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "dafc9810-8b5a-44a2-d546-542c3cbdb091"
      },
      "source": [
        "for i,e in enumerate(df.index_string):\n",
        "    if e:\n",
        "        df.index_binar[i]='0'\n",
        "    else: \n",
        "        df.index_binar[i]='0'"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C5Bne3ZIzBw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "2527172d-bc74-4520-b5b1-e899b42790ba"
      },
      "source": [
        "df.to_csv(episode_binar_mess, encoding='utf-8', index=False)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYsX4krSIzB0",
        "colab_type": "text"
      },
      "source": [
        "Vorhandene Zuordnung laden und den verschiedenen Wörtern eindeutige Zahlen zuordnen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-qAHWtYIzB0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "56767d90-e8d9-4e87-e470-9e792814eee6"
      },
      "source": [
        "mapped_episoden_2 = []\n",
        "pbar = pyprind.ProgBar(len(df['episode']),\n",
        "                       title='Episoden Zahlen zuordnen')\n",
        "for episode in df['episode']:\n",
        "    mapped_episoden_2.append([word_to_int.get(word) for word in episode.split()])\n",
        "    pbar.update()\n",
        "\n",
        "mapped_episoden_2 = [list(filter(None, el)) for el in mapped_episoden_2]\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Episoden Zahlen zuordnen\n",
            "0% [##############################] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:00:00\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BneiWwWGIzB5",
        "colab_type": "text"
      },
      "source": [
        "raiingsndaten und Trainingslabels bestimmen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KDNsqZRIzB5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "5b98ce47-3293-4d01-c102-764f7902d7d3"
      },
      "source": [
        "mess_data = mapped_episoden_2[0:] \n",
        "mess_labels = df.loc[0:, 'index_binar'].values\n",
        "print(\"sequences =\",max([max(sequences) for sequences in mapped_episoden if len(sequences)>0]),\" \", \n",
        "      \"mess_data =\", len (mess_data))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "sequences = 2593   mess_data = 158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCn04UHJIzB9",
        "colab_type": "text"
      },
      "source": [
        "Messdaten vektorisieren"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOyCPM66IzB-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3b5ed851-c269-4449-8fb7-155407e56d9b"
      },
      "source": [
        "def vectorize_sequences(sequences, dimension=sequences_laenge+1): \n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.\n",
        "    return results\n",
        "x_mess = vectorize_sequences(mess_data)\n",
        "y_mess = np.asarray(mess_labels).astype('float32')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFLkm8-XIzCC",
        "colab_type": "text"
      },
      "source": [
        "## Messdaten analysieren"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78KWykuSIzCD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "db6049ee-7ded-42ff-af21-8317b3c37cfc"
      },
      "source": [
        "plt.plot(range(1, len(average_binary_accuracy_history) + 1), average_binary_accuracy_history)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation acc')\n",
        "plt.show()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCu20tuTIzCF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "73048d2a-5fa1-44dd-9307-b7e05701c782"
      },
      "source": [
        "def smooth_curve(points, factor=0.9):\n",
        "  smoothed_points = []\n",
        "  for point in points:\n",
        "    if smoothed_points:\n",
        "      previous = smoothed_points[-1]\n",
        "      smoothed_points.append(previous * factor + point * (1 - factor))\n",
        "    else:\n",
        "      smoothed_points.append(point)\n",
        "  return smoothed_points\n",
        "\n",
        "smooth_binary_accuracy_history = smooth_curve(average_binary_accuracy_history[1:])\n",
        "\n",
        "plt.plot(range(1, len(smooth_binary_accuracy_history) + 1), smooth_binary_accuracy_history)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation acc')\n",
        "plt.show()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEGCAYAAACtqQjWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hUZfbA8e9JgdBbQi9BehcIgVAVXQELCBaKDRtVELuuu7/dxXVRUVeQIlXBhoCArqjgIgrSQwvSA9K7EDqEhPP7Y27ciIGEMJObmTmf55mHO/e95dwtOfOW+76iqhhjjDHeEOJ2AMYYYwKHJRVjjDFeY0nFGGOM11hSMcYY4zWWVIwxxnhNmNsBuCkyMlKjo6PdDsMYY/zKypUrj6hqVEZlQZ1UoqOjiY+PdzsMY4zxKyKy83Jl1vxljDHGayypGGOM8RpLKsYYY7zGkooxxhivsaRijDHGayypGGOM8RpLKsYYY7zGkkqQ+3nvcb5et9/tMIwxASKoX34MdrMT9vPU1DUkp1xk4E3VeOrmaoiI22EZY/yYJZUgpKqMWbCd177ZREylYlQskZ/h87Zy+nwKf7mtliUWY0y2WVIJMimpF/nrF+v5dPku7mhQlqF31ydPaAiFI8KZ8NMvnElO5Z931iU0xBKLMebqWVIJIifPXaD/J6tZsOUw/W6owrO31CDESR5/u6M2+fOEMuqHbZxNTuHNexoQFmpdbsaYq2NJJUjsP36Wh99fwdZDp3itSz26xVb8XbmI8Hz7mhTIG8bQOZs5k5zKuz0akjcs1KWIjTH+yH6KBoH1+45z58hF7Dl2lvd7NvlDQkmv/41V+dsdtZm74SCPTYrnbHJqDkZqjPF3llQC3PxNh7j3vSWEijC9bxytq2e4BMLvPNyiMm/cVZ+fEo/w0MTlnDx3IQciNcYEAksqAezDpTt5dNIKoiMLMLN/C2qWLpzlc+9tUoFh3Rqyatcx7hu/jGOnk30YqTEmUFhSCUAXLyr/+nojf531MzfUKMnU3nGUKhxx1dfp2KAs793fmE0HTtJt7FIOnTzng2iNMYHEkkqAOXchlf6frGLsgu08GFeJsQ80pkDe7I/HuLl2Kd7v2YRdR8/QdcxS9iad9WK0xphAY0klgBw5dZ7u45by7foD/OW2WvyjYx2vDAtuUTWSDx+N5cjJ89z73hJ2HDnthWiNMYHIkkqASDx0is6jFrFx/wlG39eYx1pd59U342Oii/Npr2acSU7hnjFL2HLwpNeubYwJHJZUAsDS7b9y1+jFnE1OZUqvONrXLe2T+9QtV4TPeschQNcxS1i357hP7mOM8V+WVPzczNV7eGDCMiIL5mFmvxZcX6GoT+9XvVQhpvaOI3+eMHqMW0r8jqM+vZ8xxr9YUvFTqsrweVt56rO1NK5UjBl9W1CheP4cuXd0ZAGm9YkjslBeHpiwnJ+2HsmR+xpjcj9LKn4oOeUiz01P4O3vttClYTkmP9KUIvnDczSGskXz8VnvZlQsnp9HPljBfzcczNH7G2NyJ58mFRFpLyKbRSRRRF7MoLySiMwTkQQR+UFEyqcrqygic0Vko4hsEJFoZ/8TzvVURCLTHV9ERP4jImtFZL2IPOzLZ3PL8bMX6Pn+cqav3MOgm6vx1r0NyBPmzm+DkoUimNKrGTXLFKLPRyv5z9p9rsRhjMk9fPbXSERCgZFAB6A20F1Eal9y2JvAZFWtDwwGhqQrmwwMVdVaQCxwyNm/CLgZ2HnJtfoDG1S1AXAD8JaI5PHeE7lvz7Ez3D16MSt2HOXNexow6Obqrq99UqxAHj5+rCmNKhZj4JTVTF2x29V4jDHu8uVP3FggUVW3q2oyMAXodMkxtYHvne35aeVO8glT1e8AVPWUqp5xtler6o4M7qdAIfH8lS0IHAVSvPtI7knYk8SdIxdz4MQ5Jj0Sy92Ny2d+Ug4pFBHOpEdiaVk1kuc/T+D9Rb+4HZIxxiW+TCrlgPQ/W/c4+9JbC3RxtjvjSQolgOpAkojMEJHVIjLUqflcyQigFrAPWAc8qaoXLz1IRHqJSLyIxB8+fPjqn8oFc9cfoOuYpUSEhzCzX3OaV4nM/KQcli9PKOMfiuGW2qX4x382MHJ+otshGWNc4HZH/bNAGxFZDbQB9gKpeNZ5aeWUNwGuA3pmcq12wBqgLHA9MEJE/jCDoqqOVdUYVY2Jisp8xl63TfzpF3p/tJLqpQoys18LqpYs5HZIl5U3LJSR9zWi0/VlGTpnM298uwlVdTssY0wO8uUiXXuBCum+l3f2/UZV9+HUVESkIHCXqiaJyB5gjapud8pmAc2ACVe438PAa+r5K5YoIr8ANYHlXnqeHJV6UXnlqw18sHgH7eqU4p2uDcmXJ/cvmBUeGsLb917/2yqSZ5JT+b/ba/+2wqQxJrD5MqmsAKqJSGU8yaQb0CP9Ac7oraNOM9VLwMR05xYVkShVPQy0BeIzud8u4CZgoYiUAmoA2731MDnpTHIKAz9dw383HuTRlpX58621/GrN+NAQ4V+d65E/TxgTfvqF0+dTeO2u+n71DMaY7PFZ85eqpgBPAHOAjcBUVV0vIoNFpKNz2A3AZhHZApQCXnXOTcXT9DVPRNYBAowDEJGBTk2mPJAgIuOda70CNHeOnwe8oKp+91beoZPn6DpmKd9vOsjgTnX46+21/fKPsYjwl9tqMfCmakxbuYcnp6zmQuofuriMMQFGgrnNOyYmRuPjM6sA5ZwtB0/y8PsrOHo6mRE9GnJTrVJuh+QVY37cxpBvNnFzrZKM6NGIiPDc34xnjLk8EVmpqjEZlbndUW8cP209wl2jFnMh9SLT+sQFTEIB6N2mCq90qsN/Nx7i0UkrOH0+YEZ6G2MuYUklF5gav5ue7y+nbNF8zOzfgrrlirgdktc9EBfNm/c0YMm2X3lw4nKOn7V1740JRJZUXKSqvDV3M89PTyCuSgmm9Y2jXNF8boflM3c3Ls+IHo1I2JNEj3FLOWrr3hsTcCypuOR8SiqDPlvDu98n0q1JBSb2bELhiJydFNINt9Yrw9gHY0g8dIquY5Zw8ISte29MILGk4oKkM8k8MGE5X6zZx3PtajCkSz3CvbDsr7+4sUZJPng4ln1JZ7l3zBL2HDvjdkjGGC8Jnr9kucTOX0/TZfRi1uxKYnj3hvS/sarrk0K6Ia5KCT56rCnHTidzz3tL2H74lNshGWO8wJJKDlq58xidRy3m6OlkPn68KR0blHU7JFc1rFiMKb3iSE65yL1jlrLpwAm3QzLGXCNLKjnk63X76TFuKYUjwpjZrwVNoou7HVKuULtsYT7rHUdYiNB1zFLW7k5yOyRjzDWwpOJjqsqYH7fR7+NV1C1XhBn9WlA5soDbYeUqVUsWZFqfOArnC+O+8ctYtv1Xt0MyxmSTJRUfSkm9yF9m/cyQbzZxe/0yfPxYU4oXCKh1w7ymQvH8TOvdnFKF8/LQ+8v5cYt/LEtgjPk9Syo+cup8Co9NjufjZbvoe0MVhndraNOTZKJ0kQg+6x3HdZEFeXxSPHPWH3A7JGPMVbKk4gMHjp/jnveWsHDrEYZ0qccL7Wva1O9ZFFkwL58+3ow65QrT7+NVzFq9N/OTjDG5hiUVL9uw7wR3jlzE7qNnmNizCd1jK7odkt8pkj+cDx9tSpPoYjw1dQ2fLNvldkjGmCyypOJF8zcf4p73FiMC0/rE0aZ67l9ZMrcqmDeMDx6O5YbqUfx55jrGL/TLpXGMCTqWVLzk42U7eWxSPJVKFGBmvxbUKvOHlYzNVYoID2XMAzHcWq80/5y9keHzttryxMbkcr5c+TEoXLyovD5nE2N+3M6NNaJ4t0cjCua1/1i9JU9YCMO7NSRf+Dre/m4Lp8+n8GKHmkE5C4Ex/sD++l2DcxdSeWbqWmav28/9zSry9zvqEBZEc3jllLDQEIbeXZ/8eUIZs2A7p5NTGNyxrg1+MCYXsqSSTb+eOs/jk+NZvTuJl2+txWOtKtuvZx8KCREGd6pD/ryhjPlxO2eSU3njrvqWxI3JZSypZMP2w6fo+f4KDp44x6gejehQr4zbIQUFEeHF9jUpmCeMt77bwtnkVIZ1a0ieMEssxuQWllSyYW/SWc6npPJpr2Y0qljM7XCCiogw4KZq5MsTyj9nb+Tsh/G8d39je7HUmFxCgnk0TUxMjMbHx2fr3HMXUu0Pmcs+Xb6LP89cR9PKxRn/UBMbIGFMDhGRlaoak1GZtRtkkyUU93WPrcg7Xa9nxY5j3D9+GcfP2Lr3xrjNkorxa52uL8eo+xqxYd8Juo1bypFT590OyZig5tOkIiLtRWSziCSKyIsZlFcSkXkikiAiP4hI+XRlFUVkrohsFJENIhLt7H/CuZ6KSOQl17tBRNaIyHoR+dGXz2Zyj3Z1SjOhZwy/HDnFXaMXs81WkTTGNT5LKiISCowEOgC1ge4iUvuSw94EJqtqfWAwMCRd2WRgqKrWAmKBQ87+RcDNwM5L7lcUGAV0VNU6wD3efSKTm7WqFsUnjzfj1LkUuoxazJJttiaLMW7wZU0lFkhU1e2qmgxMATpdckxt4Htne35auZN8wlT1OwBVPaWqZ5zt1aq6I4P79QBmqOou57hDGRxjAlijisWY1b8FUYXy8uDEZXy+co/bIRkTdHyZVMoBu9N93+PsS28t0MXZ7gwUEpESQHUgSURmiMhqERnq1HyupDpQzGlGWykiD2Z0kIj0EpF4EYk/fNgWggo0FYrn5/O+zYmtXJxnpq3lrbmbbb4wY3KQ2x31zwJtRGQ10AbYC6TieX+mlVPeBLgO6JnJtcKAxsBtQDvgryJS/dKDVHWsqsaoakxUlM0iHIiK5Avng4dj6RpTgXe/T2TglDWcu5DqdljGBAVfDuzfC1RI9728s+83qroPp6YiIgWBu1Q1SUT2AGtUdbtTNgtoBky4wv32AL+q6mngtIgsABoAW7z0PMaPhIeG8Npd9YiOLMDr325iX9JZxj7QmBIF87odmjEBzZc1lRVANRGpLCJ5gG7Al+kPEJFIEUmL4SVgYrpzi4pIWlWiLbAhk/t9AbQUkTARyQ80BTZ64TmMnxIR+t5QhVH3NeLnvcfpPGoxiYdsZJgxvuSzpKKqKcATwBw8f9ynqup6ERksIh2dw24ANovIFqAU8Kpzbiqepq95IrIOEGAcgIgMdGoy5YEEERnvnLMR+BZIAJYD41X1Z189n/Eft9Yrw5RezTiTnEKXUYtYvO2I2yEZE7BsmpZsTtNi/M/uo2d45IMV/HLkNEO61OOemAqZn2SM+QObpsUYPCPDpvdtTrPrSvDc9ASGztnExYvB+6PKGF+wpGKCSpF84bz/cBO6x1Zg5PxtDJyy2kaGGeNFNq2rCTrhoSH8q3M9oksUYMg3npFh4x6MsZFhxniB1VRMUBIRerepwuj7GrF+3wnuHLWIxEMn3Q7LGL9nScUEtQ7OyLCzyal0GbWYxYk2MsyYa2FJxQS9hhWLMbNfC0oVjuDBicuZGr8785OMMRmypGIMzpxh/ZoTV6UEz09P4I1vbWSYMdlhScUYR+GIcCb2bEL32IqM+mEbA2xkmDFXzUZ/GZOOZ2RYXSpH5v/dyLBIGxlmTJZkWlNx5u6KSPc9X9oqjMYEIhGhV2vPyLCN+0/Q2UaGGZNlWWn+mgZcTPc91dlnTEBrX7cMn/WK42zyRTqPWswiGxlmTKayklTCnJUbAXC28/guJGNyjwYVijKrf3PKFsnHQxOX89mKXW6HZEyulpWkcjjdrMKISCfAfrKZoFG+WH6m9Y0jrkoJXvh8Ha/byDBjLisrSaUP8GcR2SUiu4AXgN6+DcuY3CVtZFiPphUZ/cM2BnxqI8OMyUimo79UdRvQzFmZEVW1VY5MUAoPDeHVO+tSuUQB/vXNRvY6I8OiCtnIMGPSZGX0179EpKiqnlLVUyJSTET+mRPBGZPbiAiPt76O0fc1ZtMBz8iwrQdtZJgxabLS/NVBVZPSvqjqMeBW34VkTO7Xvm5pPusVx/mUi3QZtZiftlo3ozGQtaQSKiK/1e9FJB9g9X0T9Dwjw1pQtmg+er6/nCnLbWSYMVlJKh/jWSv+URF5FPgOmOTbsIzxD+WK5mN63ziaV43kxRnreO0bGxlmgltWOupfF5EE4CZn1yuqOse3YRnjPwpFhDPxoRj+9uV63vtxG7uOnubte68nIjzU7dCMyXFZmvtLVb8BvvFxLMb4rbDQEP55Z10qRxbg1a83sjdpKeNtZJgJQlkZ/dVMRFaIyCkRSRaRVBE5kRPBGeNPRITHWl3He/c3ZsuBk9w5chFbbGSYCTJZ6VMZAXQHtgL5gMeAkb4Myhh/1q5Oaab2jiM59SJ3jVrMwq2H3Q7JmByTpfVUVDURCFXVVFV9H2iflfNEpL2IbBaRRBF5MYPySiIyT0QSROQHESmfrqyiiMwVkY0isiFtZmQRecK5nopIZAbXbCIiKSJyd1ZiNMYX6pUvwqz+LShXLB8931/BpzYyzASJrCSVMyKSB1gjIm+IyFNZOU9EQvHUaDoAtYHuIlL7ksPeBCaran1gMDAkXdlkYKiq1gJigUPO/kXAzcDOy9zzdWBuFp7LGJ8qVzQf0/rE0bJqJC/NWMeQrzfayDAT8LKSVB5wjnsCOA1UAO7KwnmxQKKqbndmNp4CdLrkmNrA9872/LRyJ/mEqep34JkaRlXPONurVXXHZe45APic/yUgY1xVKCKcCQ/FcH+zioxZsJ1+H6/ibLLNGWYCV6ZJRVV3quo5VT2hqv9Q1aed5rDMlAN2p/u+x9mX3lqgi7PdGSgkIiWA6kCSiMwQkdUiMtSphVyWiJRzrjE6k+N6iUi8iMQfPmxt3cb3wkJDeKVTXf5yWy3mbDhAt7FLOHTynNthGeMTbq9R/yzQRkRWA22AvXgWAQsDWjnlTYDrgJ6ZXOsd4AVVvXilg1R1rKrGqGpMVFTUNYZvTNakjQwbc39jthw8ReeRi9l8wEaGmcDjy6SyF09TWZryzr7fqOo+Ve2iqg2Bl519SXhqNWucprMUYBbQKJP7xQBTRGQHcDcwSkTu9MqTGOMltzgjwy6kXuTu0YtZsMVqyyaw+DKprACqOWvc5wG6AV+mP0BEIkUkLYaXgInpzi0qImlVibbAhivdTFUrq2q0qkYD04F+qjrLO49ijPekHxn28Acr+HjZH8acGOO3sjKKq7qIjHOG936f9snsPKeG8QQwB9gITFXV9SIyON1KkjcAm0VkC1AKeNU5NxVP09c8EVkHCDDOiWegiOzBU/NJEJHxV/nMxriubNF8TO/bnFbVInl55s+8OnuDjQwzAUFUr/w/ZBFZC7wHrMTT3wGAqq70bWi+FxMTo/Hx8W6HYYJYSupFBn+1gclLdtKuTine6dqQfHlszjCTu4nISlWNyagsK3N/pajqFUdUGWOyJyw0hH90rEN0iQK8MnsDXccuYfxDMZQsFOF2aMZkS1b6VP4jIv1EpIyIFE/7+DwyY4KEiPBIy8qMfSCGrTYyzPi5rCSVh4DngMV4msBWAtZmZIyX/al2qd9Ght01ejHfbTjodkjGXLWsvPxYOYPPdTkRnDHBpl75InzxRAuiI/Pz+OR4Xv92EympV3z1yphcJSujv8KdEVfTnc8TIhKeE8EZE4zKFMnH9D7N6R5bkdE/bOOBCcs5fPK822EZkyVZaf4aDTQGRjmfxmQyFYox5tpEhIcypEs93rynAat2HeO24QtZseOo22EZk6msJJUmqvqQqn7vfB7GM3WKMcbH7m5cnln9W5A/Tyjdxi5l/MLtZPYagDFuykpSSRWRKmlfROQ60r2vYozxrVplCvPlgJbcVLMk/5y9kX4fr+LkuQtuh2VMhrKSVJ4D5juLaP2IZ6r6Z3wbljEmvcIR4Yx5oDF/vrUmczccpOOIRWw6YKt6m9wnK6O/5gHVgIF41iupoarzfR2YMeb3RIReravwyWNNOXU+hTtHLmLGqj1uh2XM71w2qYhIW+ffLsBtQFXnc5uzzxjjgqbXlWD2gJbUL1+Up6eu5eWZ6zifYi3SJne40jQtbfA0dd2RQZkCM3wSkTEmUyULR/DJY00ZOmczYxZsZ93e44zs0YgKxfO7HZoJclmZULKyqv6S2T5/ZBNKmkAwZ/0Bnp26ltBQ4d9dr+fGGiXdDskEuCtNKJmVjvrPM9g3/dpCMsZ4S7s6pfnPgJaULhzBIx+s4O25m0m1afSNSy7b/CUiNYE6QJFL+lAKAzaFqjG5SHRkAWb2a8Ffv/iZ4d8nsnp3EsO6NaR4gTxuh2aCzJVqKjWA24GiePpV0j6NgMd9H5ox5mrkyxPK0Lvr81qXeiz75Si3DV/Iql3H3A7LBJms9KnEqeqSHIonR1mfiglUP+89Tp+PVnLwxDlevrUWDzWPRkTcDssEiGtdpGu1iPTH0xT2W7OXqj7ipfiMMV5Wt1wRZg9oxdNT1/D3/2xg5a4kXutSjwJ5s/J/eWOyLysd9R8CpYF2wI941oa3FYSMyeWK5A9n3IMxPNeuBrMT9tFp5CISD9n/dY1vZSWpVFXVvwKnVXUSnhchm/o2LGOMN4SECP1vrMqHjzbl2OlkOo5YxJdr97kdlglgWUkqaTPXJYlIXaAIYAPhjfEjLapGMntgK2qVKczAT1fz9y/Xk5xii38Z78tKUhkrIsWAvwJfAhuAN3walTHG60oXiWBKr2Y82rIyHyzeQdexS9h//KzbYZkAk+nor0Bmo79MsJqdsJ/np68lb3gow7s1pGW1SLdDMn4kW6O/ROTpK11UVd/Owo3bA8OAUGC8qr52SXklYCIQBRwF7lfVPU5ZRWA8UAHPXGO3quoOEXkCGARUAaJU9Yhz/H3AC4DgGUjQV1XXZhajMcHotvplqFmmEH0/WskDE5fx9M3V6X9jVUJCbNixuTZXav4q5HxigL5AOefTB88LkFckIqHASKADUBvoLiK1LznsTWCyqtYHBgND0pVNBoaqai0gFjjk7F8E3AzsvORavwBtVLUe8AowNrMYjQlmVaIKMqt/Czo1KMtb323h0UkrSDqT7HZYxs9dNqmo6j9U9R94hhA3UtVnVPUZPGvUV8zCtWOBRFXdrqrJwBSg0yXH1MYzEzLA/LRyJ/mEqep3TiynVPWMs71aVXdkEO9iVU17fXipE7cx5gry5wnj312v55U76/JT4hFuG/4TCXuS3A7L+LGsdNSXAtL/fEl29mWmHLA73fc9zr701gJp84p1BgqJSAmgOp7RZjNEZLWIDHVqPln1KPBNRgUi0ktE4kUk/vDhw1dxSWMCk4jwQLNKTOvTHIC7Ry/h42U7Ceb+VpN9WUkqk4HlIvJ3Efk7sAz4wEv3fxZoIyKr8azfshdIxdPX08opbwJcB/TMygVF5EY8SeWFjMpVdayqxqhqTFRU1DU/gDGB4voKRfnPgJY0q1KCl2f+zDNT13I22Rb/MlcnK8sJvwo8DBxzPg+r6pArnwV4EkSFdN/LO/vSX3ufqnZR1YbAy86+JDy1mjVO01kKMIus9ePUx9O530lVf81CjMaYdIoXyMP7PZsw6OZqzFyzlztHLmL74VNuh2X8yJWWEy7s/Fsc2IFnupYPgZ3OvsysAKqJSGURyQN0w/OeS/p7RIpIWgwv4RkJlnZuURFJq0q0xfN+zGU5o8VmAA+o6pYsxGeMyUBoiDDo5up88HAsh06eo+OIRXz78363wzJ+4ko1lU+cf1cC8ek+ad+vyKlhPAHMATYCU1V1vYgMFpGOzmE3AJtFZAuefppXnXNT8TR9zRORdXiGCY8DEJGBIrIHT80nQUTGO9f6P6AEMEpE1oiIvYBizDVoUz2Krwa2okrJgvT5aBWvzt7AhVR7C99cmb38aC8/GnNF51NSeXX2RiYv2UmT6GKM6NGIUoVtnb5gdqWXHy+bVETkin0YqrrKC7G5ypKKMVn3xZq9vPj5OgrkDePd7g2Jq1LC7ZCMS7K7nspbVyhTPP0cxpgg0en6ctQqU5g+H63kvvFLea5dTfq0uc4W/zK/c9mkoqo35mQgxpjcr3qpQnz5REte+DyB17/dxKpdx3jzngYUyRfudmgml8jSMnDOlPe1+f3Kj5N9FZQxJvcqmDeMEd0b0rhiMf719UY6jviJUfc1ok7ZIm6HZnKBTN9TEZG/Ae86nxvxTHvf8YonGWMCmojwSMvKfNa7GecupNJl1GKmrtid+Ykm4GXljfq7gZuAA6r6MNAAz0Jdxpgg17hScWYPbEXjSsV4/vMEnp++lnMX7C38YJaVpHJWVS8CKc4LkYf4/ZvyxpggFlkwLx8+2pQnbqzK1Pg9dBm1mF2/nnE7LOOSrCSVeBEpiuflw5XAKmCJT6MyxviV0BDh2XY1mNgzhr1JZ7nt3YV8t+Gg22EZF1xpmpaRItJCVfupapKqvgf8CXjIaQYzxpjfaVuzFF8NaEmlEvl5fHI8r3+7iRR7Cz+oXKmmsgV4U0R2iMgbItJQVXeoakJOBWeM8T8Viudnep/mdI+tyOgftnH/hGXsP37W7bBMDrnSIl3DVDUOz5T0vwITRWSTiPxNRKrnWITGGL8TER7KkC71ePOeBqzdfZx2/17AF2v2Zn6i8XtZmfp+p6q+7kxP3x24E88EkcYYc0V3Ny7PN0+2omrJgjw5ZQ0DPl1tSxYHuKy8pxImIneIyMd4VlPczP9WazTGmCuKjizA1N5xPNeuBt+s20+7dxawYIutuhqortRR/ycRmYhnwazHgdlAFVXtpqpf5FSAxhj/FxYaQv8bqzKrfwsKRYTz4MTl/O2Ln21lyQB0pZrKS8BioJaqdlTVT1T1dA7FZYwJQHXLFeGrAS15pEVlJi3ZyW3vLmTt7iS3wzJedKWO+raqOl5Vj+VkQMaYwBYRHsr/3VGbjx9rytnkVLqMXsyw/261occBIisvPxpjjNe1qBrJt4Nac0f9Mvz7v1u4670lbD98yu2wzDWypGKMcU2RfOG8060hI3o0ZMeR09w6fCEfLt1JMK9I6+8sqRhjXHd7/bLMGdSaJtHF+eusn+n5/goOnjjndlgmGyypGGNyhdJFIpj8SCyDO9Vh2S+/0u6dBcxO2O92WOYqWVIxxuQaIsKDcdHMHn7COksAABBpSURBVNiKSsXz0/+TVTz12RqOn73gdmgmiyypGGNynSpRBZnetzmDbq7Gl2v30eGdBSxOPOJ2WCYLLKkYY3Kl8NAQBt1cnc/7NiciPJQe45fxylcbbBGwXM6nSUVE2ovIZhFJFJEXMyivJCLzRCRBRH4QkfLpyiqKyFwR2SgiG0Qk2tn/hHM9FZHIdMeLiAx3yhJEpJEvn80YkzOur1CU2QNb8WBcJSb89At3vPsTP+897nZY5jJ8llREJBQYCXQAagPdRaT2JYe9CUxW1frAYGBIurLJwFBVrQXE4llxEmARcDOw85JrdQCqOZ9ewGjvPY0xxk358oQyuFNdJj0Sy/GzF+g8ahEj5yeSetGGHuc2vqypxAKJqrpdVZOBKUCnS46pDXzvbM9PK3eST5iqfgegqqdU9YyzvVpVd2Rwv054EpSq6lKgqIiU8fZDGWPc06Z6FHOfas0tdUozdM5m7h2zhJ2/2uxRuYkvk0o5YHe673ucfemt5X8zHncGColICaA6kCQiM0RktYgMdWo+13o/RKSXiMSLSPzhwzZTqjH+pmj+PIzo3pBh3a5ny8GTdBi2kE+X77IXJnMJtzvqnwXaiMhqPIuB7QVSgTCglVPeBLgO6OmNG6rqWFWNUdWYqKgob1zSGJPDRIRO15djzqDWNKxYlJdmrOOxSfEcPnne7dCCni+Tyl6gQrrv5Z19v1HVfaraxVkA7GVnXxKeWsYap+ksBZgFZNbxnun9jDGBpWzRfHz4SFP+7/ba/JR4hHbvLGDO+gNuhxXUfJlUVgDVRKSyiOQBugFfpj9ARCJFJC2Gl4CJ6c4tKiJpVYm2wIZM7vcl8KAzCqwZcFxV7XVcYwJcSIjwSMvKfDWgJWWLRtD7w5U8N20tJ8/ZC5Nu8FlScWoYTwBz8Cw/PFVV14vIYBHp6Bx2A7BZRLYApYBXnXNT8TR9zRORdYAA4wBEZKCI7MFTE0kQkfHOtb4GtgOJzrH9fPVsxpjcp1qpQszo24InbqzK56v20GHYQpZt/9XtsIKOBHPnVkxMjMbHx7sdhjHGy1buPMbTU9ew6+gZerW6jqdvqU7esMzG+pisEpGVqhqTUZnbHfXGGON1jSsV4+uBregeW5ExC7bTacQiNu4/4XZYQcGSijEmIBXIG8a/OtdjYs8YjpxKptOIRYz5cZu9MOljllSMMQGtbc1SzBnUihtrRjHkm010H7uU3UfPuB1WwLKkYowJeCUK5uW9+xvz5j0N2LD/BB2GLWRa/G57YdIHLKkYY4KCiHB34/J882QrapctzHPTE+j94Up+PWUvTHqTJRVjTFCpUDw/nz7ejD/fWpMfNh+m3TsLmLfxoNthBQxLKsaYoBMaIvRqXYUvB7QgqlAEj06K56UZCZw+n+J2aH7PkooxJmjVLF2YWf2b06dNFaas2E2HYQtZufOo22H5NUsqxpigljcslBc71OSzXnFcVOWe95YwdM4mklMuuh2aX7KkYowxQGzl4nw7qDX3NK7AyPnb6DxqEVsOnnQ7LL9jScUYYxwF84bx+t31GftAYw4cP8ft7/7EhJ9+4aK9MJllllSMMeYSt9QpzZynWtO6WhSvfLWB+ycsY2/SWbfD8guWVIwxJgORBfMy7sHGvH5XPdbuTqL9Owv4fOUee2EyE5ZUjDHmMkSErk0q8s2TralZuhDPTFvL/ROW8cuR026HlmtZUjHGmExULJGfz3rF8c8765Kw5zjt3lnA8HlbOZ+S6nZouY4lFWOMyYKQEOH+ZpWY93Qbbqldire/28KtthDYH1hSMcaYq1CycAQjejTi/YebcD7lIl3HLuX56Ws5djrZ7dByBUsqxhiTDTfWKMl3T7WhT5sqzFi1l5ve/tE68rGkYowx2ZYvj+dt/K8GtiS6RH6embaW+8YvY/vhU26H5hpLKsYYc41qli7M9D7NebVzXdbtPU77dxYy7L/B2ZFvScUYY7wgJES4r2kl5j3ThvZ1S/Pv/26hw7CFLNkWXB35llSMMcaLShaKYHj3hkx6JJYLqRfpPm4pz05by9Eg6ci3pGKMMT7QpnoUcwe1od8NVZi1ei83vfUD04OgI9+nSUVE2ovIZhFJFJEXMyivJCLzRCRBRH4QkfLpyiqKyFwR2SgiG0Qk2tlfWUSWOdf8TETypDt+voisdq53qy+fzRhjMpMvTyjPt6/J7IGtuC6qIM9OW0v3cUvZFsAd+T5LKiISCowEOgC1ge4iUvuSw94EJqtqfWAwMCRd2WRgqKrWAmKBQ87+14F/q2pV4BjwqLP/L8BUVW0IdANGef+pjDHm6tUoXYhpveMY0qUeG/adoMM7C/n3d1s4dyHwOvJ9WVOJBRJVdbuqJgNTgE6XHFMb+N7Znp9W7iSfMFX9DkBVT6nqGRERoC0w3TlnEnCns61AYWe7CLDP+49kjDHZExIidI+tyLxnbqBDvdIMm7eVW4ctZPG2I26H5lW+TCrlgN3pvu9x9qW3FujibHcGColICaA6kCQiM5zmrKFOzacEkKSqKRlc8+/A/SKyB/gaGJBRUCLSS0TiRST+8OHD1/aExhhzlaIK5WVYt4ZMfiSWlItKj3HLeGZq4HTku91R/yzQRkRWA22AvUAqEAa0csqbANcBPTO5VnfgA1UtD9wKfCgif3g+VR2rqjGqGhMVFeW1BzHGmKvRunoUc59qTf8bq/DFmr20fesHpsbv9vuOfF8mlb1AhXTfyzv7fqOq+1S1i9MP8rKzLwlPDWSN03SWAswCGgG/AkVFJCyDaz4KTHWusQSIACJ98WDGGOMNEeGhPNeuJl8/2YqqUQV5fnoC3cYuJfGQ/3bk+zKprACqOaO18uDpPP8y/QEiEpmuNvESMDHduUVFJK0q0RbYoJ4UPh+429n/EPCFs70LuMm5bi08ScXat4wxuV71UoWY2juO17rUY+P+E3QYtoC3/bQj32dJxalhPAHMATbiGZm1XkQGi0hH57AbgM0isgUoBbzqnJuKp+lrnoisAwQY55zzAvC0iCTi6WOZ4Ox/BnhcRNYCnwI91d/rkcaYoBESInRzOvJvq1eG4fO20mHYQhYn+ldHvgTz392YmBiNj493OwxjjPmDhVsP85dZP7Pz1zN0aViOl2+rRYmCed0OCwARWamqMRmVud1Rb4wxJgOtqkUxZ1BrBrStyn8S9nHT2z8ydUXu78i3pGKMMblURHgoz9xSg68HtqJayYI8/3kCXccuJfHQSbdDuyxLKsYYk8tVK1WIz3rF8fpd9dh84CQdhi3krbmbc2VHviUVY4zxAyEhQtcmFZn3TBtur1+Wd79PpP07C/hpa+7qyLekYowxfiSyYF7+3fV6Pnq0KQD3T1jGoCmrOXLqvMuReVhSMcYYP9SyWiTfDmrNwLZVmb1uPze99SNTlu/i4kV3O/ItqRhjjJ+KCA/l6Vtq8M2TrahRqhAvzlhH17FL2HrQvY58SyrGGOPnqpYsxJRezXjjrvpsPXSKW4cv5M057nTkW1IxxpgAEBIi3NukAvOebsMdDcoyYn4i7d5ZwMKtOTtblSUVY4wJICUK5uXte6/nk8eaEiLCAxOW8+SU1Rw+mTMd+ZZUjDEmADWvGsk3T7Zi4E3V+Hrdfm566wc+zYGOfEsqxhgToCLCQ3n6T9X55snW1CxTmJdmrOPeMUvY4sOOfEsqxhgT4KqWLMhnvZox9O76JB4+xa3DFjJ+4Xaf3Css80OMMcb4OxHhnpgKtK1Zkn99vYnoEgV8ch9LKsYYE0RKFMzLW/c28Nn1rfnLGGOM11hSMcYY4zWWVIwxxniNJRVjjDFeY0nFGGOM11hSMcYY4zWWVIwxxniNJRVjjDFeI6rurhLmJhE5DOzM5umRQO5aHDr77Flyp0B5lkB5DrBnSVNJVaMyKgjqpHItRCReVWPcjsMb7Flyp0B5lkB5DrBnyQpr/jLGGOM1llSMMcZ4jSWV7BvrdgBeZM+SOwXKswTKc4A9S6asT8UYY4zXWE3FGGOM11hSMcYY4zWWVK6SiEwUkUMi8rPbsVwrEakgIvNFZIOIrBeRJ92OKTtEJEJElovIWuc5/uF2TNdKREJFZLWIfOV2LNdCRHaIyDoRWSMi8W7Hcy1EpKiITBeRTSKyUUTi3I7paolIDee/i7TPCREZ5NV7WJ/K1RGR1sApYLKq1nU7nmshImWAMqq6SkQKASuBO1V1g8uhXRUREaCAqp4SkXDgJ+BJVV3qcmjZJiJPAzFAYVW93e14sktEdgAxqur3LwyKyCRgoaqOF5E8QH5VTXI7ruwSkVBgL9BUVbP7EvgfWE3lKqnqAuCo23F4g6ruV9VVzvZJYCNQzt2orp56nHK+hjsfv/21JCLlgduA8W7HYjxEpAjQGpgAoKrJ/pxQHDcB27yZUMCSinGISDTQEFjmbiTZ4zQXrQEOAd+pql8+h+Md4HngotuBeIECc0VkpYj0cjuYa1AZOAy87zRLjheRAm4HdY26AZ96+6KWVAwiUhD4HBikqifcjic7VDVVVa8HygOxIuKXTZMicjtwSFVXuh2Ll7RU1UZAB6C/03zsj8KARsBoVW0InAZedDek7HOa7zoC07x9bUsqQc7pg/gc+FhVZ7gdz7VymiTmA+3djiWbWgAdnb6IKUBbEfnI3ZCyT1X3Ov8eAmYCse5GlG17gD3pasDT8SQZf9UBWKWqB719YUsqQczp4J4AbFTVt92OJ7tEJEpEijrb+YA/AZvcjSp7VPUlVS2vqtF4mie+V9X7XQ4rW0SkgDMABKep6BbAL0dNquoBYLeI1HB23QT41YCWS3THB01f4KnSmasgIp8CNwCRIrIH+JuqTnA3qmxrATwArHP6IwD+rKpfuxhTdpQBJjmjWUKAqarq10NxA0QpYKbntwthwCeq+q27IV2TAcDHTtPRduBhl+PJFifB/wno7ZPr25BiY4wx3mLNX8YYY7zGkooxxhivsaRijDHGayypGGOM8RpLKsYYY7zGkooxPiAiqZfMBuu1t69FJDoQZsk2gcneUzHGN84608YYE1SspmJMDnLWF3nDWWNkuYhUdfZHi8j3IpIgIvNEpKKzv5SIzHTWilkrIs2dS4WKyDhn/Zi5zkwCiMhAZ32cBBGZ4tJjmiBmScUY38h3SfNX13Rlx1W1HjACz4zEAO8Ck1S1PvAxMNzZPxz4UVUb4Jlrar2zvxowUlXrAEnAXc7+F4GGznX6+OrhjLkce6PeGB8QkVOqWjCD/TuAtqq63ZnM84CqlhCRI3gWTLvg7N+vqpEichgor6rn010jGs/0/tWc7y8A4ar6TxH5Fs8icrOAWenWmTEmR1hNxZicp5fZvhrn022n8r/+0duAkXhqNStExPpNTY6ypGJMzuua7t8lzvZiPLMSA9wHLHS25wF94beFyIpc7qIiEgJUUNX5wAtAEeAPtSVjfMl+xRjjG/nSzfwM8K2qpg0rLiYiCXhqG92dfQPwrCr4HJ4VBtNmwH0SGCsij+KpkfQF9l/mnqHAR07iEWB4ACx5a/yM9akYk4OcPpUYVT3idizG+II1fxljjPEaq6kYY4zxGqupGGOM8RpLKsYYY7zGkooxxhivsaRijDHGayypGGOM8Zr/B9/lHgno0YZ1AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbKUe0Q6IzCK",
        "colab_type": "text"
      },
      "source": [
        "Modell ausführen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHFGOPqvIzCL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "b233b843-5365-4b5b-c165-cee7b9c8ca33"
      },
      "source": [
        "# Get a fresh, compiled model.\n",
        "model = build_model()\n",
        "# Train it on the entirety of the data.\n",
        "model.fit(x_train, y_train,\n",
        "          epochs = 1, batch_size = 1)\n",
        "mess_mse_score, mess_binary_accuracy_score = model.evaluate(x_mess, y_mess)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "368/368 [==============================] - 2s 4ms/step - loss: 0.0712 - binary_accuracy: 0.9212\n",
            "158/158 [==============================] - 0s 195us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQQ8tHhJIzCR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "168973be-e984-4e36-e39f-97093edcb0f3"
      },
      "source": [
        "mess_binary_accuracy_score, mess_mse_score"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9303797483444214, 0.05925303782466092)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeO3Q7tQIzCT",
        "colab_type": "text"
      },
      "source": [
        "Voraussagen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6xyXoGbIzCU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "a8d68f34-c343-4f31-8e63-bb600688c4f4"
      },
      "source": [
        "predictions=model.predict(x_mess)\n",
        "#for i in range(len(predictions)):\n",
        "    #print(model.predict(x_mess))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s74ij7H3IzCe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "de9a0515-243d-4548-899b-7d39f0e421be"
      },
      "source": [
        "print('Maximaler Wert:', max(max(model.predict(x_mess))))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Maximaler Wert: 0.9998495\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FARaGkLGIzCk",
        "colab_type": "text"
      },
      "source": [
        "Voraussgen in den aussortierten Datensätzen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6h6mWCGYIzCl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "88c66672-be74-4f65-b012-fde004c6b1e0"
      },
      "source": [
        "mod_pred = model.predict(x_mess)\n",
        "cutoff_value = 0.3\n",
        "for i in range(len(y_mess)):\n",
        "    if mod_pred[i,0]>cutoff_value:\n",
        "        if ((i==0)|(mod_pred[i-1,0]>cutoff_value))|(mod_pred[i+0]>cutoff_value):\n",
        "            #if df.index_string ==0:\n",
        "                print (i+0,\"-\",\n",
        "                  #i+2,\"-\", \n",
        "                  #y_test[i],\"-\", \n",
        "                  mod_pred[i],\"-\",\n",
        "                  df.quelle[i+0],\"-\", \n",
        "                  df.episode[i+0],\"-\",\n",
        "                  df.index_string[i+0],'\\n')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "14 - [0.48857078] - mess_44 - hinter mir dunkel und vorne mir klar - 0 \n",
            "\n",
            "15 - [0.6092753] - mess_44 - dass niemand sehe wohin ich fahr - 0 \n",
            "\n",
            "49 - [0.47021177] - mess_49 - seine hexenkunst hat hans nie mehr ausgeuebt da er bei seinem ersten versuch so viel angst hat ausstehen muessen und wenn einmal die rede aufs hexen kam soll hans immer gesagt haben das ist nichts fuer rechtschaffene leute - 0 \n",
            "\n",
            "56 - [0.48426786] - mess_52 - damit war die muehle und die heerde von den riesen erloest und der jaeger ueber alle jaeger setzte seine reise fort er kam in eine stadt die ganz mit flor ueberzogen war weil ein drache die koenigstochter vom markte abholen wollte da stellte der jaeger ueber alle jaeger sich mit seinen treuen hunden neben die prinzessin und als der drache kam rief er ihm zu was du an den koenig zu fordern hast kannst du auch an mich fordern in demselben augenblicke sprangen die drei hunde stahl eisen und hille gegen den drachen an und zerrissen ihn - 0 \n",
            "\n",
            "70 - [0.9998495] - 0_e300c - kneten frass wasser gruetze dannen kurz frug abendessen demjenigen naehe retten darum dunkelwelt geselle toeten wirtshaus halten versuchen rede ass gefallen betruebt mensch seid einzige seien maedchen hurtigundgeschwind jedesmal gesellen verhaengt boeser krone brief drach geraubt nacheinander ueberzogen uhr fragt finde kind erste witwe fahnen geben bedeuten wirth meermanne geopfert fresse ausgeliefert muessen gleichen herberge gast uebrigen dach frassen muessten antwortete behangen bedingung haeuser toechtern unsres grossmutters jungfrau schoene geb reich damals drache alljaehrlich loos tochter wirt verschlang haeuschen schwarz koenigreichs grade flor naechste erloesen ach sei uebergeben schuster menschen befreien trauer fragte versprochen schwarzem traurig stadt warum reihe - 0 \n",
            "\n",
            "89 - [0.5921154] - grimm_nr_96 - er kam an das wasser und da ging es ihm ebenso wie seinem bruder - e707_o_bei_der_erfuellung_der_vorletzten_herausforderung_aufgabe_des_ziels \n",
            "\n",
            "103 - [0.69466835] - mess_47 - dieser aber war in die stadt getreten wo er alles in bestuerzung und trauer fand alle fenster waren mit schwarzen tuechern verhangen er erkundigte sich daher was die ursache solcher trauer waere und erfuhr dass riesen in der naehe wohnten welche die stadt immer in angst und schrecken hielten und dass sieben drachen in einer nahen hoehle hausten welchen sie jeden tag einen menschen opfern muessten  und endlich sey eine schlange nicht weit auf einem baume welche alle menschen verzehre die ungluecklicher weise in ihr bereich kaemen niemand aber waere zu finden welcher die stadt von diesen ungeheuern befreyen wollte - 0 \n",
            "\n",
            "104 - [0.73669183] - mess_47 - nun sey das loos auf die koenigstochter gefallen283 dass sie des uebermorgigen tages den drachen geopfert werden solle der koenig habe zwar verkuenden lassen dass wer diese ungeheuer erlegen wuerde die koenigstochter zur ehe und spaeter das koenigreich als erbe haben sollte aber niemand finde sich der ein so gefaehrliches unternehmen wagen wollte - 0 \n",
            "\n",
            "111 - [0.52306056] - mess_47 - der schneider wurde inne dass ihn die koenigstochter hasse und den grund warum wie er daher wieder zu bette ging stellte er sich als traeume er wieder und diesesmal von lauter schlachten und siegen - 0 \n",
            "\n",
            "112 - [0.4486698] - mess_47 - da wurde die koenigstochter noch trauriger und ging 286 am morgen wieder zum koenige und meldete ihm was ihr gatte heute nacht getraeumt habe worueber aber ihr das herz brechen wollte das erfuellte das herz des koenigs mit freude - 0 \n",
            "\n",
            "113 - [0.4334888] - mess_47 - er ertheilte noch am naemlichen tage dem eidam den befehl das heer gegen den feind zu fuehren liess ihm aber doch seiner tochter zu gefallen die schlechteste ruestung und das schlechteste pferd geben zugleich befahl er ihm stets an der spitze des heeres zu bleiben - 0 \n",
            "\n",
            "117 - [0.34420788] - mess_47 - von da an lebten sie noch lange und gluecklich tiefenbach - 0 \n",
            "\n",
            "118 - [0.32432398] - mess_46 - es war einmal in einem kleinen fischerdorf ein armer fischer der dort mit seiner frau lebte sie hatten keine kinder - 0 \n",
            "\n",
            "120 - [0.4126302] - mess_46 -  lass mich noch einen tag wachsen dann kannst du mich fangen und essen - 0 \n",
            "\n",
            "122 - [0.33762494] - mess_46 - er nahm ihn also vom haken und warf ihn wieder ins meer - 0 \n",
            "\n",
            "130 - [0.8759956] - mess_46 -  ach mein kind wir haben hier kein wasser in dieser gegend hier lebt eine lamia die das wasser unter verschluss haelt wir bekommen nichts wenn sie nicht jeden tag ein maedchen zu fressen bekommt und morgen wird sie die koenigstochter rodanthi fressen - 0 \n",
            "\n",
            "131 - [0.5474212] - mess_46 - als der junge mann das hoerte fragte er wo denn die lamia waere - 0 \n",
            "\n",
            "132 - [0.39297444] - mess_46 -  dort drueben sagte sie - 0 \n",
            "\n",
            "133 - [0.762323] - mess_46 - da brach er auf und ging an den ort an dem man die koenigstochter behuetete und wo die lamia sie fressen wuerde - 0 \n",
            "\n",
            "134 - [0.34127244] - mess_46 -  ich werde dich retten sagte er ihr du musst nicht weinen - 0 \n",
            "\n",
            "135 - [0.573706] - mess_46 - kurz darauf hoerte er ein droehnen und sah die lamia kommen - 0 \n",
            "\n",
            "136 - [0.3559661] - mess_46 -  oha sagte sie da heute werde ich gleich zwei zu fressen haben - 0 \n",
            "\n",
            "139 - [0.4173956] - mess_46 - dann kam der tag an dem der koenig seinem schwiegersohn das ganze koenigreich zeigen wollte sie reisten fort und kamen eines tages vor eine riesige burg - 0 \n",
            "\n",
            "141 - [0.36594093] - mess_46 - der junge mann aber beachtete den hinweis nicht weiter den ihm der koenig gegeben hatte und zog am naechsten tag los um alle leute zu befreien die die lamia gefangen hielt - 0 \n",
            "\n",
            "142 - [0.38849688] - mess_46 - er schlug an die pforte und hoerte eine kraeftige stimme von innen - 0 \n",
            "\n",
            "147 - [0.5199632] - mess_46 - er klopfte an die pforte und auch er hoerte eine kraeftige stimme - 0 \n",
            "\n",
            "154 - [0.46398696] - mess_53 - der gluecksvogel freite jetzt die prinzessin und der alte erkannte ihn als koenig an - 0 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRs1MX7BIzCn",
        "colab_type": "text"
      },
      "source": [
        "Voraussage: gewünschte Datensetze abrufen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfq52ia7IzCo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d1408521-d5b6-490f-820a-c2e5478b40c1"
      },
      "source": [
        "for i in range(len(x_mess)):\n",
        "    if i>121:\n",
        "        print(i+0,\"-\",\n",
        "              model.predict(x_mess)[i],\"-\",\n",
        "              df.quelle[i+0],\"-\",\n",
        "              df.episode[i+0],\"-\",\n",
        "              df.index_string[i+0],'\\n')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "122 - [0.33762494] - mess_46 - er nahm ihn also vom haken und warf ihn wieder ins meer - 0 \n",
            "\n",
            "123 - [0.14186662] - mess_46 - als er am abend nach hause kam und seiner frau erzaehlte was er gesehen und gehoert hatte wurde sie boese weil sie nichts zu essen hatten - 0 \n",
            "\n",
            "124 - [0.28305387] - mess_46 - am naechsten morgen ging der fischer wieder zum fischen und fing das goldene fischchen noch einmal da sagte es ihm - 0 \n",
            "\n",
            "125 - [0.25014424] - mess_46 -  jetzt gehoere ich dir du kannst mich essen aber bevor du mich isst werde ich dir einen ratschlag geben den du in deinem eigenen interesse befolgen solltest iss ein stueckchen und gib deiner frau auch eines zu essen dann wird sie zwillinge gebaeren danach nimm meine graeten und vergrab sie vor deinem haus dann werden zwei zypressen daraus spriessen dann nimm ein paar von ihren blaettern und fuettere alle tiere die du hast und sie werden auch zwillinge gebaeren - 0 \n",
            "\n",
            "126 - [0.2582993] - mess_46 - und so geschah es nach einiger zeit bekamen sie zwei jungen zwillinge die beiden aehnelten einander so sehr dass man sie nicht voneinander unterscheiden konnte und auch die huendin und die katze bekamen zwillinge - 0 \n",
            "\n",
            "127 - [0.09309313] - mess_46 - eines tages sahen sie noch etwas seltsames zusammen mit den wurzeln der zypressen die vor ihrem hause gewachsen waren sprossen auch zwei schwerter als die kinder groesser waren wollte eines von ihnen auswandern da nahm das kind eines der pferde einen der hunde und eines der schwerter bevor es loszog sagt es zu seiner mutter - 0 \n",
            "\n",
            "128 - [0.12112629] - mess_46 -  mutter ich habe ein zeichen in die ablage gemacht solange das zeichen dort ist geht es mir gut wenn es herunterfaellt dann schick meinen bruder um nach mir zu suchen denn dann befinde ich mich in gefahr - 0 \n",
            "\n",
            "129 - [0.04391569] - mess_46 - er brach auf und zog sehr weit fort unterwegs traf er eine alte frau die ihn in ihrer huette aufnahm und bewirtete als sie ihm zu essen gab bat der junge um etwas wasser und da sagte ihm die alte frau - 0 \n",
            "\n",
            "130 - [0.8759956] - mess_46 -  ach mein kind wir haben hier kein wasser in dieser gegend hier lebt eine lamia die das wasser unter verschluss haelt wir bekommen nichts wenn sie nicht jeden tag ein maedchen zu fressen bekommt und morgen wird sie die koenigstochter rodanthi fressen - 0 \n",
            "\n",
            "131 - [0.5474212] - mess_46 - als der junge mann das hoerte fragte er wo denn die lamia waere - 0 \n",
            "\n",
            "132 - [0.39297444] - mess_46 -  dort drueben sagte sie - 0 \n",
            "\n",
            "133 - [0.762323] - mess_46 - da brach er auf und ging an den ort an dem man die koenigstochter behuetete und wo die lamia sie fressen wuerde - 0 \n",
            "\n",
            "134 - [0.34127244] - mess_46 -  ich werde dich retten sagte er ihr du musst nicht weinen - 0 \n",
            "\n",
            "135 - [0.573706] - mess_46 - kurz darauf hoerte er ein droehnen und sah die lamia kommen - 0 \n",
            "\n",
            "136 - [0.3559661] - mess_46 -  oha sagte sie da heute werde ich gleich zwei zu fressen haben - 0 \n",
            "\n",
            "137 - [0.03795788] - mess_46 - sobald sie sich ihnen naeherte nahm der junge mann das schwert das er hinter einigen steinen versteckt hatte warf die lamia zu boden und toetete sie daraufhin ging er und oeffnete die quellen seitdem hatten sie in der gegend wieder wasser - 0 \n",
            "\n",
            "138 - [0.02976084] - mess_46 - dann kehrte er in die huette der alten frau zurueck sie kuesste ihn dankte ihm und schlug ihm vor mit ihr weiter zusammen zu wohnen die koenigstochter aber verliebte sich in ihn und wollte ihn zu ihrem mann haben er war einverstanden sie heirateten und lebten gluecklich miteinander - 0 \n",
            "\n",
            "139 - [0.4173956] - mess_46 - dann kam der tag an dem der koenig seinem schwiegersohn das ganze koenigreich zeigen wollte sie reisten fort und kamen eines tages vor eine riesige burg - 0 \n",
            "\n",
            "140 - [0.15723631] - mess_46 -  geh niemals in diese burg hinein denn dort versteckt sich eine lamia die alle gefangen nimmt die hineinkommen sagte der koenig zu seinem schwiegersohn - 0 \n",
            "\n",
            "141 - [0.36594093] - mess_46 - der junge mann aber beachtete den hinweis nicht weiter den ihm der koenig gegeben hatte und zog am naechsten tag los um alle leute zu befreien die die lamia gefangen hielt - 0 \n",
            "\n",
            "142 - [0.38849688] - mess_46 - er schlug an die pforte und hoerte eine kraeftige stimme von innen - 0 \n",
            "\n",
            "143 - [0.2661212] - mess_46 -  wenn du waffen hast dann wirf sie nieder und komm rein - 0 \n",
            "\n",
            "144 - [0.01132238] - mess_46 - er legte sein schwert ab trat ein und kaempfte lange zeit erbittert mit der lamia er schaffte es aber nicht sie zu besiegen so wurde auch er einer ihrer gefangenen in dem augenblick in dem der junge mann gefangen genommen wurde fiel zu hause das zeichen von der ablage als das seine mutter sah begann sie zu weinen und alle glaubten dass er verloren gegangen waere - 0 \n",
            "\n",
            "145 - [0.20453924] - mess_46 - da begab sich sein bruder auf den weg um nach ihm zu suchen zufaellig kam auch er an der alten frau vorbei die seinen bruder bewirtet hatte sie dachte dass es sich um seinen bruder handelte der die lamia umgebracht hatte und dankte ihm - 0 \n",
            "\n",
            "146 - [0.0560686] - mess_46 - von dort begab sich der zwillingsbruder zum palast des koenigs als ihn die frau seines bruders sah hielt sie ihn fuer ihren mann am morgen ging er hinaus und tat so als wuerde er auf jagd gehen zufaellig schlug er denselben weg ein der zur burg fuehrte als er nach seinem bruder suchte stand er mit einem mal vor der grossen burg in der die lamia wohnte - 0 \n",
            "\n",
            "147 - [0.5199632] - mess_46 - er klopfte an die pforte und auch er hoerte eine kraeftige stimme - 0 \n",
            "\n",
            "148 - [0.20431033] - mess_46 -  wenn du waffen hast leg sie ab und komm herein - 0 \n",
            "\n",
            "149 - [0.0783298] - mess_46 - der junge mann aber trat ein ohne sein schwert draussen zu lassen er zog sein schwert brachte die lamia um und befreite seinen bruder und alle anderen - 0 \n",
            "\n",
            "150 - [0.05502099] - mess_46 - sie kehrten in den palast zurueck auch ihre eltern kamen dorthin und sie lebten alle zusammen gut und wir leben noch besser - 0 \n",
            "\n",
            "151 - [0.00042218] - mess_53 - in einem holze wohnte ein mann der hatte zwei zwillinge von denen war der eine ein gluecksvogel der andere ein pechvogel der mann aber saeete auf ein stuecklein landes eine saat daraus wuchsen auf zwei schwerter zwei pudelhunde und zwei schimmel als seine soehne nun funfzehn jahre alt waren gab er jedem eins von den schwertern einen von den pudelhunden und einen von den schimmeln und damit zogen sie in die weite welt wie sie an den kreuzweg kamen nahmen sie abschied und verabredeten dass sie einander durch die hunde nachricht geben wollten wer zuerst sein glueck in einer stadt machte solle seinen hund an diesen kreuzweg bringen dann werde der schon aufspueren wo der andere bruder sei nun kommt aber der pechvogel in ein wirthshaus wo die wirthin eine hexe ist die erwuergt ihn schneidet seinen leib entzwei und steckt ihn in einen tubben dann erwuergt sie auch seinen hund wiewol der den namen hatte brichstahlundeisen schneidet ihn auch auseinander und steckt ihn auch in den tubben der gluecksvogel kommt in eine stadt die stadt ist ganz mit schwarzem flor ueberzogen an diesem tage holt naemlich ein drache eine prinzessin ab weil er jedes jahr an diesem tage ein maedchen von funfzehn jahren wegholen muss und weil diesmal kein maedchen von funfzehn jahren da ist als die prinzessin er beschliesst die prinzessin zu retten und mit dem drachen zu kaempfen er geht also auf den drachenberg ein diener des koenigs fuehrt die prinzessin dahin wie der drache die prinzessin sieht kommt er ploetzlich aus der luft geschossen der gluecksvogel haut 20 muthig auf den drachen los sein kluger hund der den namen hatte bringspeise und sein treues pferd helfen ihm dabei so kriegt er den drachen mit sieben koepfen nieder und schneidet aus den sieben koepfen die zungen heraus die prinzessin aber gibt ihm einen ring und ein tuch worin ihr name steht sie will ihn sogleich mit aufs schloss nehmen er aber gedenkt seines bruders und reitet mit seinem treuen hunde bringspeise zuerst nach dem kreuzwege zu der diener welcher die prinzessin bis vor den berg in der kutsche begleitet hat haelt noch dort da er nun den abschied der prinzessin von dem ritter gehoert hat droht er ihr unterwegs sie zu toedten wenn sie nicht sagen wolle dass er sie erloest habe aus angst schwoert sie ihm endlich dies zu er nimmt sieben hunde und schneidet ihnen die zungen aus um sie dem koenige als die zungen des drachen vorzulegen das geschieht der koenig aber ist hocherfreut und verspricht dem diener die krone bald danach wird die verlobung der prinzessin gehalten der edle ritter ist aber nun auf den kreuzweg gekommen von dort verfolgt der treue hund die spur in ein wirthshaus und der ritter folgt ihm auf seinem pferde dahin dort winselt sein hund und wie er sein pferd in den stall zieht da meckert es ordentlich vor freude und daraus merkt er dass seines bruders pferd daneben im stalle steht - 0 \n",
            "\n",
            "152 - [0.0026135] - mess_53 - nun fragt er die alte frau in dem wirthshause hin und her erhaelt aber keine nachricht von seinem bruder endlich legt er sich nieder in tiefen gedanken weil er in dem wirthshause niemand weiter gesehen hat als diese alte frau wie es gegen elf uhr abends ist wird der hund bringspeise unruhig er springt auf und ergreift den degen tritt an die thuer und hoert die wirthin sprechen ein herr liegt hier auf der stube dem wollen wir an den kragen so kommen zwoelf hexen worunter die wirthin zur thuer 21 herein und er haut elf davon nieder die wirthin aber will entlaufen doch greift er sie in der thuer und sagt sie muesse sterben wenn sie seinen bruder nicht herbeischaffe die alte hexe verspricht ihn herbeizuschaffen holt den tubben und nimmt daraus ein stueck nach dem andern von seinem bruder bestreicht die stuecken mit hexensalbe aus dem glase und hext den pechvogel wieder zusammen darauf nimmt sie aus der tonne zuerst die schnauze dann die andern theile des hundes brichstahlundeisen hext die auch wieder zusammen und der hund brichstahlundeisen springt freudig heulend an dem neuerstandenen pechvogel in die hoehe nun schwingen sich beide brueder auf die pferde da ruft die alte hexe den gluecksvogel geruehrt dass er ihr allein das leben geschenkt hat noch einmal um gibt ihm noch etwas von der salbe und sagt man koenne nicht wissen was dem pechvogel noch einmal geschaehe wenn holland in noth sei bei ihm dann solle er ihn nur mit der hexensalbe bestreichen sie bat sich zur belohnung nur ein paar haare von seinem pudelhunde bringspeise aus - 0 \n",
            "\n",
            "153 - [0.0140586] - mess_53 - so zieht der gluecksvogel mit dem pechvogel einmuethig in die stadt des koenigs da aber ist alles froehlich da fragt der ritter warum alles so froehlich sei und bekommt die antwort die koenigstochter habe hochzeit nun macht der ritter mit dem wirthe eine wette dass er etwas von der koenigstafel erhalten werde durch seinen hund er bindet dem hunde bringspeise das tuch das er von der prinzessin erhalten hat um steckt ein briefchen hinein und befiehlt dem hunde sich von niemandem anders als von der prinzessin das tuch abbinden zu lassen der hund wird einige mal von den soldaten zurueckgetrieben schleicht sich aber endlich durch und gelangt in das hochzeitszimmer er kriecht unter den tisch zu der prinzessin fuessen und zerrt an ihrem gewande die prinzessin liest den brief thut nach dem verlangen 22 ihres wahren erloesers eine von den schuesseln die auf der koenigstafel standen in das tuch und damit kehrt der hund in den gasthof zurueck der koenig welcher sah wie seine tochter dem hunde die speise uebergab hiess seinen treuesten diener ihm nachfolgen der fand den gluecksvogel im wirthshause wie er eben mit seinem bruder sich an den tisch setzte um die speise von koenigs tafel zu verzehren da erfuhr der treue diener des koenigs von dem gluecksvogel alles und sah auch die sieben rechten drachenzungen nun ward der gluecksvogel mit seinem bruder in der kutsche nach dem koenigshofe gebracht die prinzessin bekannte dass er ihr wahrer erloeser sei und er musste ueber den falschen erloeser das urtheil sprechen der ward in eine mit naegeln beschlagene tonne gesteckt und die tonne wurde den berg heruntergerollt - 0 \n",
            "\n",
            "154 - [0.46398696] - mess_53 - der gluecksvogel freite jetzt die prinzessin und der alte erkannte ihn als koenig an - 0 \n",
            "\n",
            "155 - [0.02445375] - mess_53 - nun aber hoert was sich mit dem pechvogel noch begeben hat der gluecksvogel ging seit er koenig war wie andere koenige auch thun tagtaeglich auf die jagd um sein leben zu geniessen der pechvogel aber sass unterdessen zu hause im palaste bei der schoenen koenigin da kamen dem gluecksvogel auf der jagd einmal gedanken was wol der pechvogel daheim immer bei seiner frau zu thun habe ein koenig ist auch nur ein mensch und darum achtete der gluecksvogel des schoenen hirsches nicht der sich eben auf schussweite ihm naeherte sondern ritt heim zu seiner frau und da fand er den pechvogel wie er vor ihr sass und sie anschaute da wurde er eifersuechtig und in der eifersucht fuehlte er sich so recht als koenig zog sein schwert und hieb den pechvogel in stuecken - 0 \n",
            "\n",
            "156 - [0.26906925] - mess_53 - nun betheuerte aber die koenigin ihrem gemahl ihre und seines bruders unschuld niemals habe dieser ungebuehrliches 23 von ihr verlangt nur einmal wie er sie auch wieder so angeschaut habe er sie um einen kuss gebeten und den habe sie ihm nicht gegeben - 0 \n",
            "\n",
            "157 - [0.22168776] - mess_53 - da gereute es den koenig was er gethan und er erinnerte sich der hexensalbe welche die alte ihm auf den weg gegeben hatte damit bestrich er den pechvogel sodass dieser abermals lebendig wurde und wenn sie noch nicht gestorben sind so jagt der koenig heute noch nach dem hirsche und der pechvogel sitzt heute noch bei der koenigin - 0 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gyC7RW9IzCr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 51,
      "outputs": []
    }
  ]
}